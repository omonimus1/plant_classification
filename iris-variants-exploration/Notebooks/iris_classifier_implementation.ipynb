{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omonimus1/plant_classification/blob/development/iris-variants-exploration/Notebooks/iris_classifier_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4c4oWGlvZsMy",
        "outputId": "8c7ac033-ae04-4052-a063-365f0bb7f02c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "# load iris dataset data\n",
        "flowersPath = Path('/content/gdrive/Othercomputers/DavideLaptop/Desktop/IrisClassification')\n",
        "iris = pd.read_csv(Path('/content/gdrive/Othercomputers/DavideLaptop/Desktop/IrisClassification/iris.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "versicolors = len(iris[iris['species'] == 'versicolor'])\n",
        "virginica = len(iris[iris['species'] == 'virginica'])\n",
        "setosa =  len(iris[iris['species'] == 'setosa'])\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.axis('equal')\n",
        "classes = ['Versicolor', 'Setosa', 'Virginica']\n",
        "s = [versicolors,setosa,virginica]\n",
        "ax.pie(s, labels = classes,autopct='%1.2f%%')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "xXL6rQyS0JEJ",
        "outputId": "cd860ec8-56c8-457f-d139-3d886b9303cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YoFNbD_IZsM4",
        "outputId": "8070d61f-74c0-4b00-af1b-b9528ad4b159",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "<built-in function sum>\n"
          ]
        }
      ],
      "source": [
        "X = iris.drop('species', axis=1)\n",
        "y = iris['species']\n",
        "print('---')\n",
        "y.unique()\n",
        "print(sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xARFEF7KZsM7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "encoder = LabelBinarizer()\n",
        "y = encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qW6tjlKfZsM-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-RSKNmcmZsNA"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6JKibH6FZsNB"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "scaled_X_train = scaler.transform(X_train)\n",
        "scaled_X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPFBGV4oZsNE",
        "outputId": "d62a79dd-6d90-4067-c4f7-1b0a8495e160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 16)                80        \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 3)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 947\n",
            "Trainable params: 947\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "4/4 [==============================] - 1s 102ms/step - loss: 1.1235 - accuracy: 0.2857 - val_loss: 1.0879 - val_accuracy: 0.4889\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.1033 - accuracy: 0.3524 - val_loss: 1.0770 - val_accuracy: 0.6444\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.0831 - accuracy: 0.5810 - val_loss: 1.0736 - val_accuracy: 0.6889\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.0682 - accuracy: 0.5714 - val_loss: 1.0706 - val_accuracy: 0.5111\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.0574 - accuracy: 0.6762 - val_loss: 1.0679 - val_accuracy: 0.5556\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.0419 - accuracy: 0.7143 - val_loss: 1.0593 - val_accuracy: 0.5556\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.0274 - accuracy: 0.7143 - val_loss: 1.0478 - val_accuracy: 0.5556\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.0097 - accuracy: 0.7143 - val_loss: 1.0330 - val_accuracy: 0.5556\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.9908 - accuracy: 0.7143 - val_loss: 1.0162 - val_accuracy: 0.5556\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.9711 - accuracy: 0.7143 - val_loss: 0.9975 - val_accuracy: 0.5556\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.9494 - accuracy: 0.7143 - val_loss: 0.9783 - val_accuracy: 0.5556\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.9264 - accuracy: 0.7143 - val_loss: 0.9589 - val_accuracy: 0.5556\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.9018 - accuracy: 0.7143 - val_loss: 0.9385 - val_accuracy: 0.5556\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.8751 - accuracy: 0.7143 - val_loss: 0.9160 - val_accuracy: 0.5556\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.8455 - accuracy: 0.7143 - val_loss: 0.8915 - val_accuracy: 0.5556\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.8136 - accuracy: 0.7143 - val_loss: 0.8649 - val_accuracy: 0.5556\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7787 - accuracy: 0.7143 - val_loss: 0.8356 - val_accuracy: 0.5556\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7435 - accuracy: 0.7143 - val_loss: 0.8046 - val_accuracy: 0.5556\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.7059 - accuracy: 0.7143 - val_loss: 0.7747 - val_accuracy: 0.5556\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6694 - accuracy: 0.7143 - val_loss: 0.7480 - val_accuracy: 0.5556\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6359 - accuracy: 0.7143 - val_loss: 0.7224 - val_accuracy: 0.5556\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6038 - accuracy: 0.7143 - val_loss: 0.6971 - val_accuracy: 0.5556\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5752 - accuracy: 0.7143 - val_loss: 0.6741 - val_accuracy: 0.5556\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5494 - accuracy: 0.7143 - val_loss: 0.6536 - val_accuracy: 0.5556\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5262 - accuracy: 0.7143 - val_loss: 0.6338 - val_accuracy: 0.5556\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5057 - accuracy: 0.7143 - val_loss: 0.6193 - val_accuracy: 0.5556\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4897 - accuracy: 0.7143 - val_loss: 0.6041 - val_accuracy: 0.5556\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4706 - accuracy: 0.7143 - val_loss: 0.5784 - val_accuracy: 0.5556\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4566 - accuracy: 0.7143 - val_loss: 0.5588 - val_accuracy: 0.5556\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4410 - accuracy: 0.7143 - val_loss: 0.5479 - val_accuracy: 0.5556\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4279 - accuracy: 0.7143 - val_loss: 0.5305 - val_accuracy: 0.5556\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4153 - accuracy: 0.7143 - val_loss: 0.5135 - val_accuracy: 0.5556\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4034 - accuracy: 0.7429 - val_loss: 0.4994 - val_accuracy: 0.6222\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3931 - accuracy: 0.7619 - val_loss: 0.4944 - val_accuracy: 0.6222\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3832 - accuracy: 0.7619 - val_loss: 0.4743 - val_accuracy: 0.7333\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3705 - accuracy: 0.8190 - val_loss: 0.4504 - val_accuracy: 0.8222\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3629 - accuracy: 0.9238 - val_loss: 0.4282 - val_accuracy: 0.9111\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3589 - accuracy: 0.9524 - val_loss: 0.4127 - val_accuracy: 0.9333\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3476 - accuracy: 0.9333 - val_loss: 0.4059 - val_accuracy: 0.8667\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3328 - accuracy: 0.9143 - val_loss: 0.4016 - val_accuracy: 0.8667\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3221 - accuracy: 0.9048 - val_loss: 0.3943 - val_accuracy: 0.8444\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3134 - accuracy: 0.9048 - val_loss: 0.3847 - val_accuracy: 0.8667\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3027 - accuracy: 0.9048 - val_loss: 0.3623 - val_accuracy: 0.9111\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2895 - accuracy: 0.9619 - val_loss: 0.3350 - val_accuracy: 0.9778\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2884 - accuracy: 0.9714 - val_loss: 0.3230 - val_accuracy: 0.9778\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2781 - accuracy: 0.9524 - val_loss: 0.3250 - val_accuracy: 0.9333\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2646 - accuracy: 0.9619 - val_loss: 0.3226 - val_accuracy: 0.9333\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2580 - accuracy: 0.9619 - val_loss: 0.2993 - val_accuracy: 0.9333\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2473 - accuracy: 0.9524 - val_loss: 0.2903 - val_accuracy: 0.9556\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2390 - accuracy: 0.9524 - val_loss: 0.2853 - val_accuracy: 0.9333\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2343 - accuracy: 0.9619 - val_loss: 0.2843 - val_accuracy: 0.9333\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2233 - accuracy: 0.9619 - val_loss: 0.2615 - val_accuracy: 0.9556\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2182 - accuracy: 0.9619 - val_loss: 0.2466 - val_accuracy: 0.9778\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2087 - accuracy: 0.9619 - val_loss: 0.2593 - val_accuracy: 0.9333\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2052 - accuracy: 0.9619 - val_loss: 0.2521 - val_accuracy: 0.9333\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1967 - accuracy: 0.9619 - val_loss: 0.2312 - val_accuracy: 0.9556\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1886 - accuracy: 0.9714 - val_loss: 0.2211 - val_accuracy: 0.9778\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1817 - accuracy: 0.9619 - val_loss: 0.2104 - val_accuracy: 0.9778\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1767 - accuracy: 0.9619 - val_loss: 0.2041 - val_accuracy: 0.9778\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1711 - accuracy: 0.9619 - val_loss: 0.1988 - val_accuracy: 0.9778\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1638 - accuracy: 0.9619 - val_loss: 0.1983 - val_accuracy: 0.9556\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1589 - accuracy: 0.9714 - val_loss: 0.1972 - val_accuracy: 0.9556\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1593 - accuracy: 0.9714 - val_loss: 0.1970 - val_accuracy: 0.9556\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1480 - accuracy: 0.9714 - val_loss: 0.1739 - val_accuracy: 0.9778\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1550 - accuracy: 0.9619 - val_loss: 0.1668 - val_accuracy: 0.9556\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1448 - accuracy: 0.9619 - val_loss: 0.1754 - val_accuracy: 0.9556\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1390 - accuracy: 0.9714 - val_loss: 0.1771 - val_accuracy: 0.9556\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1353 - accuracy: 0.9714 - val_loss: 0.1624 - val_accuracy: 0.9556\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1292 - accuracy: 0.9619 - val_loss: 0.1509 - val_accuracy: 0.9778\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1271 - accuracy: 0.9714 - val_loss: 0.1476 - val_accuracy: 0.9778\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1244 - accuracy: 0.9619 - val_loss: 0.1435 - val_accuracy: 0.9778\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1213 - accuracy: 0.9714 - val_loss: 0.1431 - val_accuracy: 0.9778\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1205 - accuracy: 0.9714 - val_loss: 0.1540 - val_accuracy: 0.9556\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1169 - accuracy: 0.9714 - val_loss: 0.1385 - val_accuracy: 0.9778\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1108 - accuracy: 0.9714 - val_loss: 0.1320 - val_accuracy: 0.9778\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1102 - accuracy: 0.9619 - val_loss: 0.1301 - val_accuracy: 0.9556\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1132 - accuracy: 0.9714 - val_loss: 0.1266 - val_accuracy: 0.9778\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1062 - accuracy: 0.9714 - val_loss: 0.1250 - val_accuracy: 0.9778\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1033 - accuracy: 0.9714 - val_loss: 0.1226 - val_accuracy: 0.9778\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1014 - accuracy: 0.9714 - val_loss: 0.1199 - val_accuracy: 0.9778\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1009 - accuracy: 0.9714 - val_loss: 0.1178 - val_accuracy: 0.9778\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0983 - accuracy: 0.9714 - val_loss: 0.1173 - val_accuracy: 0.9778\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0951 - accuracy: 0.9714 - val_loss: 0.1175 - val_accuracy: 0.9778\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0958 - accuracy: 0.9619 - val_loss: 0.1227 - val_accuracy: 0.9556\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0956 - accuracy: 0.9714 - val_loss: 0.1142 - val_accuracy: 0.9556\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0901 - accuracy: 0.9619 - val_loss: 0.1087 - val_accuracy: 0.9778\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0916 - accuracy: 0.9714 - val_loss: 0.1085 - val_accuracy: 0.9556\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0903 - accuracy: 0.9714 - val_loss: 0.1064 - val_accuracy: 0.9778\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0891 - accuracy: 0.9619 - val_loss: 0.1092 - val_accuracy: 0.9556\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0855 - accuracy: 0.9619 - val_loss: 0.1025 - val_accuracy: 0.9778\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0937 - accuracy: 0.9810 - val_loss: 0.1151 - val_accuracy: 0.9556\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0983 - accuracy: 0.9714 - val_loss: 0.1003 - val_accuracy: 0.9778\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0821 - accuracy: 0.9714 - val_loss: 0.1111 - val_accuracy: 0.9556\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0902 - accuracy: 0.9714 - val_loss: 0.1111 - val_accuracy: 0.9556\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0823 - accuracy: 0.9714 - val_loss: 0.0966 - val_accuracy: 0.9778\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0786 - accuracy: 0.9714 - val_loss: 0.0980 - val_accuracy: 0.9556\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0870 - accuracy: 0.9810 - val_loss: 0.0954 - val_accuracy: 0.9778\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0777 - accuracy: 0.9714 - val_loss: 0.1002 - val_accuracy: 0.9556\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0821 - accuracy: 0.9714 - val_loss: 0.1029 - val_accuracy: 0.9556\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0810 - accuracy: 0.9714 - val_loss: 0.0951 - val_accuracy: 0.9556\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0804 - accuracy: 0.9619 - val_loss: 0.0902 - val_accuracy: 0.9778\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0760 - accuracy: 0.9714 - val_loss: 0.0896 - val_accuracy: 0.9778\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0739 - accuracy: 0.9714 - val_loss: 0.0896 - val_accuracy: 0.9778\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0756 - accuracy: 0.9714 - val_loss: 0.0879 - val_accuracy: 0.9778\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0743 - accuracy: 0.9810 - val_loss: 0.0875 - val_accuracy: 0.9778\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0735 - accuracy: 0.9714 - val_loss: 0.0868 - val_accuracy: 0.9778\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0716 - accuracy: 0.9619 - val_loss: 0.0861 - val_accuracy: 0.9778\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0709 - accuracy: 0.9619 - val_loss: 0.0846 - val_accuracy: 0.9778\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0688 - accuracy: 0.9714 - val_loss: 0.0859 - val_accuracy: 0.9778\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0717 - accuracy: 0.9810 - val_loss: 0.0845 - val_accuracy: 0.9778\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0699 - accuracy: 0.9810 - val_loss: 0.0825 - val_accuracy: 0.9778\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0687 - accuracy: 0.9619 - val_loss: 0.0861 - val_accuracy: 0.9556\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0764 - accuracy: 0.9619 - val_loss: 0.0855 - val_accuracy: 0.9556\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0687 - accuracy: 0.9619 - val_loss: 0.0872 - val_accuracy: 0.9556\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0751 - accuracy: 0.9714 - val_loss: 0.0888 - val_accuracy: 0.9778\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0718 - accuracy: 0.9810 - val_loss: 0.0798 - val_accuracy: 0.9778\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0675 - accuracy: 0.9619 - val_loss: 0.0876 - val_accuracy: 0.9556\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0749 - accuracy: 0.9714 - val_loss: 0.0893 - val_accuracy: 0.9556\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0694 - accuracy: 0.9619 - val_loss: 0.0783 - val_accuracy: 0.9778\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0634 - accuracy: 0.9810 - val_loss: 0.0815 - val_accuracy: 0.9556\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0676 - accuracy: 0.9810 - val_loss: 0.0777 - val_accuracy: 0.9778\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0638 - accuracy: 0.9810 - val_loss: 0.0765 - val_accuracy: 0.9778\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0655 - accuracy: 0.9619 - val_loss: 0.0788 - val_accuracy: 0.9556\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0651 - accuracy: 0.9619 - val_loss: 0.0762 - val_accuracy: 0.9778\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0641 - accuracy: 0.9619 - val_loss: 0.0750 - val_accuracy: 0.9778\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0625 - accuracy: 0.9810 - val_loss: 0.0756 - val_accuracy: 0.9778\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0648 - accuracy: 0.9810 - val_loss: 0.0743 - val_accuracy: 0.9778\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0638 - accuracy: 0.9810 - val_loss: 0.0765 - val_accuracy: 0.9778\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0636 - accuracy: 0.9810 - val_loss: 0.0729 - val_accuracy: 0.9778\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0627 - accuracy: 0.9619 - val_loss: 0.0737 - val_accuracy: 0.9556\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0618 - accuracy: 0.9619 - val_loss: 0.0723 - val_accuracy: 0.9778\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0606 - accuracy: 0.9714 - val_loss: 0.0730 - val_accuracy: 0.9778\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0621 - accuracy: 0.9810 - val_loss: 0.0732 - val_accuracy: 0.9778\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0608 - accuracy: 0.9810 - val_loss: 0.0708 - val_accuracy: 0.9778\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0587 - accuracy: 0.9714 - val_loss: 0.0724 - val_accuracy: 0.9556\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0631 - accuracy: 0.9619 - val_loss: 0.0736 - val_accuracy: 0.9556\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0697 - accuracy: 0.9619 - val_loss: 0.0704 - val_accuracy: 0.9778\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0637 - accuracy: 0.9714 - val_loss: 0.0727 - val_accuracy: 0.9556\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0627 - accuracy: 0.9619 - val_loss: 0.0727 - val_accuracy: 0.9556\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0605 - accuracy: 0.9619 - val_loss: 0.0690 - val_accuracy: 0.9778\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0626 - accuracy: 0.9810 - val_loss: 0.0768 - val_accuracy: 0.9778\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0647 - accuracy: 0.9810 - val_loss: 0.0727 - val_accuracy: 1.0000\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0607 - accuracy: 0.9810 - val_loss: 0.0682 - val_accuracy: 0.9778\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0642 - accuracy: 0.9714 - val_loss: 0.0750 - val_accuracy: 0.9556\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0663 - accuracy: 0.9619 - val_loss: 0.0680 - val_accuracy: 0.9778\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0601 - accuracy: 0.9619 - val_loss: 0.0686 - val_accuracy: 0.9556\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0594 - accuracy: 0.9619 - val_loss: 0.0667 - val_accuracy: 0.9778\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0577 - accuracy: 0.9810 - val_loss: 0.0674 - val_accuracy: 0.9778\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0578 - accuracy: 0.9810 - val_loss: 0.0695 - val_accuracy: 1.0000\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0624 - accuracy: 0.9810 - val_loss: 0.0705 - val_accuracy: 1.0000\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0575 - accuracy: 0.9810 - val_loss: 0.0655 - val_accuracy: 0.9778\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0598 - accuracy: 0.9714 - val_loss: 0.0722 - val_accuracy: 0.9556\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0656 - accuracy: 0.9619 - val_loss: 0.0707 - val_accuracy: 0.9556\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0585 - accuracy: 0.9619 - val_loss: 0.0647 - val_accuracy: 0.9778\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0584 - accuracy: 0.9810 - val_loss: 0.0680 - val_accuracy: 1.0000\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0574 - accuracy: 0.9810 - val_loss: 0.0644 - val_accuracy: 0.9778\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0562 - accuracy: 0.9619 - val_loss: 0.0659 - val_accuracy: 0.9556\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0602 - accuracy: 0.9619 - val_loss: 0.0652 - val_accuracy: 0.9556\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0562 - accuracy: 0.9714 - val_loss: 0.0660 - val_accuracy: 1.0000\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.0662 - val_accuracy: 1.0000\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0586 - accuracy: 0.9714 - val_loss: 0.0630 - val_accuracy: 0.9778\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0559 - accuracy: 0.9619 - val_loss: 0.0632 - val_accuracy: 0.9778\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0573 - accuracy: 0.9810 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0551 - accuracy: 0.9810 - val_loss: 0.0623 - val_accuracy: 0.9778\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0545 - accuracy: 0.9810 - val_loss: 0.0623 - val_accuracy: 0.9778\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0585 - accuracy: 0.9619 - val_loss: 0.0647 - val_accuracy: 0.9556\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0579 - accuracy: 0.9619 - val_loss: 0.0630 - val_accuracy: 0.9556\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0556 - accuracy: 0.9619 - val_loss: 0.0622 - val_accuracy: 0.9778\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0575 - accuracy: 0.9810 - val_loss: 0.0635 - val_accuracy: 1.0000\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0599 - accuracy: 0.9714 - val_loss: 0.0638 - val_accuracy: 0.9556\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0575 - accuracy: 0.9619 - val_loss: 0.0653 - val_accuracy: 0.9556\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0587 - accuracy: 0.9619 - val_loss: 0.0657 - val_accuracy: 0.9556\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0564 - accuracy: 0.9619 - val_loss: 0.0607 - val_accuracy: 0.9778\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0767 - val_accuracy: 0.9556\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0668 - accuracy: 0.9714 - val_loss: 0.0755 - val_accuracy: 0.9556\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0580 - accuracy: 0.9810 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0528 - accuracy: 0.9714 - val_loss: 0.0657 - val_accuracy: 0.9556\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0620 - accuracy: 0.9619 - val_loss: 0.0646 - val_accuracy: 0.9556\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0521 - accuracy: 0.9714 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0635 - accuracy: 0.9714 - val_loss: 0.0823 - val_accuracy: 0.9333\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0637 - accuracy: 0.9810 - val_loss: 0.0635 - val_accuracy: 1.0000\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0557 - accuracy: 0.9810 - val_loss: 0.0629 - val_accuracy: 0.9556\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0589 - accuracy: 0.9619 - val_loss: 0.0691 - val_accuracy: 0.9556\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0609 - accuracy: 0.9619 - val_loss: 0.0621 - val_accuracy: 0.9556\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0504 - accuracy: 0.9714 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0552 - accuracy: 0.9810 - val_loss: 0.0698 - val_accuracy: 0.9778\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa2dcb51d10>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(patience=10)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=16, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=16, activation='relu', input_shape=[16,]))\n",
        "model.add(Dense(units=16, activation='relu', input_shape=[16,]))\n",
        "model.add(Dense(units=16, activation='relu', input_shape=[16,]))\n",
        "\n",
        "model.add(Dense(units=3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x=scaled_X_train, y=y_train, epochs=300, validation_data=(scaled_X_test, y_test), callbacks=[early_stop])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "metrics = pd.DataFrame(model.history.history)"
      ],
      "metadata": {
        "id": "NPWqEaaPZsNH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMXT_pXmZsNI",
        "outputId": "b03d5d4a-f926-43f7-9615-5e50b681eae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]]\n",
            "[[13  0  0]\n",
            " [ 0 20  1]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ],
      "source": [
        "loss_history = pd.DataFrame(model.history.history)\n",
        "#loss_history[['loss', 'val_loss']].plot()\n",
        "model.evaluate(scaled_X_test, y_test, verbose=0)\n",
        "epochs = len(loss_history)\n",
        "#print(epochs)\n",
        "\n",
        "\n",
        "print(y_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_test_ = np.argmax(y_test, axis=1)\n",
        "y_pred = model.predict(scaled_X_test)\n",
        "class_index = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(confusion_matrix(class_index, y_test_))\n",
        "\n",
        "\n",
        "scaled_X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56dllgbaZsNI",
        "outputId": "384726e6-1d23-45f5-df0f-af9ab1d28186"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20914530754089355, 0.9555555582046509]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "b3UFKr59ZsNK",
        "outputId": "78d36534-5472-42ed-da47-8b069af7d9a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.2733\n",
            "Epoch 2/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 3/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 4/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0987 - accuracy: 0.2600\n",
            "Epoch 5/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.2667\n",
            "Epoch 6/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 7/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 8/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 9/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 10/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 11/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 12/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 13/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 14/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0987 - accuracy: 0.2200\n",
            "Epoch 15/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3133\n",
            "Epoch 16/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 17/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3067\n",
            "Epoch 18/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3000\n",
            "Epoch 19/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.2600\n",
            "Epoch 20/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 21/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 22/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 23/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 24/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0987 - accuracy: 0.2667\n",
            "Epoch 25/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 26/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.2667\n",
            "Epoch 27/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0987 - accuracy: 0.3000\n",
            "Epoch 28/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 29/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 30/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 31/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 32/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0987 - accuracy: 0.2800\n",
            "Epoch 33/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 34/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3067\n",
            "Epoch 35/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 36/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 37/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 38/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 39/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.2933\n",
            "Epoch 40/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3133\n",
            "Epoch 41/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3133\n",
            "Epoch 42/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 43/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 44/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 45/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 46/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 47/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 48/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 49/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 50/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 51/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 52/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 53/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 54/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 55/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 56/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 57/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 58/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 59/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 60/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 61/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 62/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 63/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 64/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 65/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 66/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3067\n",
            "Epoch 67/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 68/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 69/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 70/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 71/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 72/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.2667\n",
            "Epoch 73/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 74/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 75/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 76/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.2400\n",
            "Epoch 77/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3200\n",
            "Epoch 78/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 79/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 80/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 81/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 82/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 83/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 84/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 85/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 86/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 87/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 88/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 89/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 90/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 91/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 92/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3000\n",
            "Epoch 93/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3267\n",
            "Epoch 94/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.2333\n",
            "Epoch 95/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.2867\n",
            "Epoch 96/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3267\n",
            "Epoch 97/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3000\n",
            "Epoch 98/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 99/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 100/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 101/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 102/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 103/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 104/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 105/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 106/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 107/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 108/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 109/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 110/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 111/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 112/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 113/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 114/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 115/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 116/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 117/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 118/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 119/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 120/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 121/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 122/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 123/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 124/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3067\n",
            "Epoch 125/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 126/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 127/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 128/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 129/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 130/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 131/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 132/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 133/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 134/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3000\n",
            "Epoch 135/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 136/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 137/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0987 - accuracy: 0.2800\n",
            "Epoch 138/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 139/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3000\n",
            "Epoch 140/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 141/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 142/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3133\n",
            "Epoch 143/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 144/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 145/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 146/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 147/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 148/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 149/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 150/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.0986 - accuracy: 0.3067\n",
            "Epoch 151/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 152/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 153/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 154/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 155/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 156/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 157/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 158/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 159/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 160/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 161/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 162/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 163/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 164/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 165/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 166/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 167/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 168/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 169/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 170/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 171/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 172/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 173/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 174/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 175/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 176/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 177/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 178/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 179/300\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 180/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 181/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 182/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 183/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 184/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 185/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 186/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 187/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 188/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 189/300\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 190/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 191/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 192/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 193/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 194/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 195/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 196/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 197/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 198/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 199/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 200/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 201/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 202/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 203/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 204/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 205/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 206/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 207/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 208/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 209/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 210/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 211/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 212/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 213/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 214/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 215/300\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 216/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 217/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 218/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 219/300\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 220/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 221/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 222/300\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 223/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 224/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 225/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 226/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 227/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 228/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 229/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 230/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 231/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 232/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 233/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 234/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 235/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3067\n",
            "Epoch 236/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 237/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 238/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 239/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3267\n",
            "Epoch 240/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 241/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 242/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 243/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 244/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 245/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 246/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 247/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 248/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 249/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 250/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 251/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 252/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 253/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 254/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 255/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 256/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 257/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 258/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 259/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 260/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 261/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 262/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 263/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 264/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 265/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 266/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 267/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 268/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 269/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.2533\n",
            "Epoch 270/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3200\n",
            "Epoch 271/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.2867\n",
            "Epoch 272/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3200\n",
            "Epoch 273/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 274/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 275/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 276/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 277/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 278/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.0986 - accuracy: 0.3133\n",
            "Epoch 279/300\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 280/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 281/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 282/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 283/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 284/300\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 285/300\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 286/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 287/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 288/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 289/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 290/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 291/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 292/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 293/300\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 294/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3067\n",
            "Epoch 295/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 296/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.3267\n",
            "Epoch 297/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 298/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 299/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 300/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.3067\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa2e1bbc110>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "\n",
        "model.add(Dense(units=3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(scaled_X, y, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DSMnvRxIZsNL",
        "outputId": "b39128ef-b4d4-4ba9-8f7d-73d6f7e17895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving the classifier\n",
            "--loading back the classifier-- \n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "from keras.models import load_model\n",
        "\n",
        "print('saving the classifier')\n",
        "joblib.dump(scaler, 'iris_classifier.pkl')\n",
        "model.save(\"iris_classifier.h5\")\n",
        "\n",
        "print('--loading back the classifier-- ')\n",
        "iris_classifier = load_model('iris_classifier.h5')\n",
        "flower_scaler = joblib.load(\"iris_classifier.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZnBLZzA-ZsNM"
      },
      "outputs": [],
      "source": [
        "\n",
        "flower_test = {\"sepal_length\": 5.6,\n",
        "                  \"sepal_width\": 2.9,\n",
        "                  \"petal_length\": 4,\n",
        "                  \"petal_width\": 1.2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFROX5MNZsNN",
        "outputId": "c72886ae-1e9c-4f14-f6c7-e76822da8f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sepal_length': 5.6, 'sepal_width': 2.9, 'petal_length': 4, 'petal_width': 1.2}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_iris_prediction(model, scaler, request):\n",
        "    sepal_length = request[\"sepal_length\"]\n",
        "    sepal_width = request[\"sepal_width\"]\n",
        "    petal_length = request[\"petal_length\"]\n",
        "    petal_width = request[\"petal_width\"]\n",
        "    \n",
        "    flower = [[sepal_length, sepal_width, petal_length, petal_width]]\n",
        "    flower = scaler.transform(flower)\n",
        "    \n",
        "    iris_classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
        "    \n",
        "    prediction = model.predict(flower)\n",
        "    class_index = np.argmax(prediction, axis=1)\n",
        "    \n",
        "    print(iris_classes[class_index])\n",
        "\n",
        "# get_iris_prediction(iris_classifier, flower_scaler, flower_test)\n",
        "\n",
        "print(flower_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion matrix"
      ],
      "metadata": {
        "id": "jECdIYYpaIu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot non-normalized confusion matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "class_names = iris['species']\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "titles_options = [\n",
        "    (\"Confusion matrix, without normalization\", None),\n",
        "    (\"Normalized confusion matrix\", \"true\"),\n",
        "]\n",
        "for title, normalize in titles_options:\n",
        "    disp = ConfusionMatrixDisplay.from_estimator(\n",
        "        model,\n",
        "        X_test,\n",
        "        y_test,\n",
        "        display_labels=class_names,\n",
        "        # cmap=plt.cm.Blues,\n",
        "        # normalize=normalize,\n",
        "    )\n",
        "    disp.ax_.set_title(title)\n",
        "\n",
        "    print(title)\n",
        "    print(disp.confusion_matrix)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "n4WGdiBPaLzN",
        "outputId": "01485e34-3714-4b02-bf03-64b959aac044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-3e68fb1730c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mdisplay_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# cmap=plt.cm.Blues,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# normalize=normalize,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_plot/confusion_matrix.py\u001b[0m in \u001b[0;36mfrom_estimator\u001b[0;34m(cls, estimator, X, y, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mcheck_matplotlib_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{method_name} only supports classifiers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: ConfusionMatrixDisplay.from_estimator only supports classifiers"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "iris_classifier_implementation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}