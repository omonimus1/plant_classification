{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "4c4oWGlvZsMy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WjulnLXZsM3",
        "outputId": "8fdfe101-e5f1-4d4b-9fef-fbd1cc0cbf74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "# load csv data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "\n",
        "flowersPath = Path('/content/gdrive/Othercomputers/DavideLaptop/Desktop/IrisClassification')\n",
        "iris = pd.read_csv(Path('/content/gdrive/Othercomputers/DavideLaptop/Desktop/IrisClassification/iris.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "versicolors = len(iris[iris['species'] == 'versicolor'])\n",
        "virginica = len(iris[iris['species'] == 'virginica'])\n",
        "setosa =  len(iris[iris['species'] == 'setosa'])\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.axis('equal')\n",
        "classes = ['Versicolor', 'Setosa', 'Virginica']\n",
        "s = [versicolors,setosa,virginica]\n",
        "ax.pie(s, labels = classes,autopct='%1.2f%%')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "xXL6rQyS0JEJ",
        "outputId": "6de96c7f-cbcc-4bfd-c476-79406faeb012"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAEuCAYAAADx63eqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xcZd3+8c93yrZkM8lmd1OBoZewEAgtAZRqeRYUEEVFXXxQqgUbrpWxryBFEKRDsGAUpcjyUwFFHjrBIENvWSAkpGdTt879++NsIMAGkt2ZuefMud6v17wIu3POXLPJvdfcp5pzDhERkaiI+Q4gIiJSTCo+ERGJFBWfiIhEiopPREQiRcUnIiKRouITEZFIUfGJiEikqPhERCRSVHwiIhIpKj4REYkUFZ+IiESKik9ERCJFxSciIpGi4hMRkUhR8YmISKSo+EREJFJUfCIiEikqPhERiRQVn4iIRIqKT0REIkXFJyIikaLiExGRSFHxiYhIpKj4REQkUlR8IiISKSo+ERGJFBWfiIhEiopPREQiRcUnIiKRouITEZFIUfGJiEikqPhERCRSVHwiIhIpKj4REYmUhO8AIuUo3dpeDYx5y2MUwZiLE3zoNCAH9A881gIrgOUbPDo72ppdsfOLlDNzTmNKZHOkW9srga0HHtts8NgaGA+MBirz9HI5oBNYCrwEzAVe3PDR0da8NE+vVVRm9i+gzTn39w2+dgawo3Pu1CGu80PALs65tiEsu9o5N3IoryvhouITeQfp1vYJwLQNHlOByQSztVLRCTwJPLLB48mOtuZ+r6nehZmdBEx3zn12g689AJzpnLv7XZaNO+fy+v42p/jMLOGc68vn60vxqPhEBqRb26uAAwYe64tugtdQQ7cOeIygBB8E7uxoa37Vb6Q3M7M64GlgsnOux8zSwN3A54EMwaz5BeCzzrnVZtYBzAIOB84GGoFTgD7gSefcx83sBGAv59wXzGwccCnBbBzgVOfcfWb2VeB/B752pXPugoE8q51zI83MBtb/QcABP3bOzTKzg4AfEWyC3sk5t0NhfjJSaNrHJ5GVbm03YA+CX6SHERRelddQ+VMN7DvwOA0g3dr+FHAHcDtwV0db8yp/8cA5t8zMHiIomJuBjwP/AL4DHOacW2Nm3wS+CvxwYLGlzrk9AcxsPrC1c67bzEYP8hIXAv92zh1tZnFgpJlNAz5L8HMx4EEz+7dzbs4Gyx1DMLPfHagHHjaz9TPQPYFdnXNz8/VzkOJT8UmkpFvbU8BRwP8AhxD8YouKnQceXwT60q3tDxIUzZ872pqf8JTpeoLCW198NxL8/dwbTLyoAO7f4PmzNvjzY8DvzOwm4KZB1n0I8BmAgc2inWZ2AHCjc24NgJn9BTgQ2LD4DgCuH1hmoZn9G9gbWAk8pNILPxWflL10a3st8CHgOOD9BL9Moy4B7D/w+EG6tf0J4I/ArI625meKmONm4Hwz2xOoAf4D3O6c+8RGnr9mgz83A+8BjgS+Y2ZNBU369teXkNI+PilL6db2GoJfiMcRbEorl02YxfBfgpnVrI625hcL/WJmNgvYkaAEf0WwX/IQ59zzZjYCmOSce3ZgH99ezrklZhYDtnTOdZhZkuCI110IZovr9/H9AXjAOXfB+k2dwLbAtcB+DGzqBD7tnJuzwT6+Y4CTCbYK1AGzCTaN7gR83Tl3RKF/JlJYmvFJWUm3tu9CsE/r0wTnzcnm233g8dN0a/u/gEuAmzramgt1FOP1BJs4P+6cWzxwgMr1Zrb+lJDvAs++ZZk48FszSxEU2IXOuRUDm0fX+zJwuZmdSHCe5KnOufvN7FrgoYHnXPmW/XsMZJlO8AHAERxl+pqZ7ZSH9yolQDM+Cb10a3sSOJqg8N7rOU65mg9cAVze0dY833cYkeFQ8UlopVvbJxIczv45wnvaQdj0MbBJsqOt+S7PWUSGRMUnoZNubd8C+BbBuVj5ukKKbL4HgB91tDXf5juIyOZQ8UlopFvb08C3gRZ0ZGYpmU1QgLf4DiKyKVR8UvLSre3bEJzU/Gkg6TmObNwcgiub3KQLa0spU/FJyUq3to8juGLH/6IjkMPkUeBrHW3N//QdRGQwKj4pOQPXzPwKwX68Ws9xZOhuBb5e5BPiRd6Vik9KSyZ11CpX/dU9ui/br4+ENmuGXy9wEfCDjrbmlb7DiICKT0pFJrUjwUWF3wfw275D//3dvhN1Tl75eA34JvAb7f8T31R84lcmFSf4hXgWGxyp6Ryde3X/uncpqShdRDoK7gRO7Ghrfsl3EImumO8AEmGZ1C4EV97/CW85PcGM1FUVv3jKSy4ppEOBbLq1/WTfQSS6NOOT4gtmed/gjZuNDso5ckf3/PC5R912OxYrmhTVHQSzv5d9B5Fo0YxPiiuT2hm4D/gZ73LVFTNi11Scva4oucSHw4DH063tJ/kOItGiGZ8UTyZ1KnA+m3mZsbN6Wx6Y2f/+/QoTSkpEO/Dpjrbm5b6DSPlT8UnhZVIjgEuBTw1l8T4Xmzel++r6bip0T73y1gF8tKOtebbvIFLetKlTCiuT2ongZp9DKj2AhOUmn528/IH8hZISlQbuSbe2n+o7iJQ3zfikcDKp44ArCe58PSzOsWb/7gtXzqdetx+Kht8BJ3e0Na/xHUTKj4pP8i+TSgDnAV/M52qfzU26730958zI5zqlpD0BfESXPJN806ZOya9MqpbgQIW8lh7A9vbq9ANi2Wy+1yslawpwX7q1/UDfQaS8qPgkfzKpicDdDFx2LN/MsEuT58dBmykipA64Pd3afpzvIFI+VHySH5nUFII7ck8t5MuMtK5dvhC/6d5CvoaUnErg+nRr+zd8B5HyoH18MnyZ1MHAX4DRxXi5fmcLd+u+csQaqod90IyEzsXAlzramnO+g0h4acYnw5NJfQL4G0UqPYC4uXEXJn/1SLFeT0rK6cBfBu7ZKDIkKj4ZukzqM8BvecsFpovhkNic/ba2+brGYzR9GLhF5SdDpeKToQlK7xo8/Rsyo/K65M8X+HhtKQmHo/KTIVLxyebzXHrrbRFbvO/7Yw/N8ZlBvFL5yZCo+GTzlEjprXdB8pKRMXL9vnOINyo/2Wwl8ctLQqLESg+g2nq2b01cr9Mbok3lJ5tFpzPIpsmkjgL+TAmV3no5Z8v26L4s1snIoh1ZKiXpFuBoneog76bkfolJCcqk9gV+T4n+e4mZq7u84rzHfOcQ7z4EXOg7hJS+kvxFJiUkk9oW+CtQ7TvKO9nHnp6xi3W84DuHeHd6urX9675DSGlT8cnGZVL1wP8DGnxHeTdmJK6t+PkK3zmkJJydbm3/mO8QUrpUfDK4TKqaYJ/J9r6jbKpG65z20fhdD/vOId4ZcJ3u6iAbo4Nb5O0yKQNuAI7xHWVz9bhEx5Tuqyf2kij61WSk5CwHput+fvJWmvHJYL5FCEsPoML60j9KXHO/7xxSEsYQXNdzhO8gUlpUfPJmmdQhwA99xxiO4+L/2qOeFYt955CSsAtwme8QUlpUfPKG4Eay1wNx31GGw4xR11Sco81bst7x6db2U32HkNKh4pNAJpUAZgGNvqPkw642d8Ze9sxTvnNIyTg/3dq+l+8QUhpUfLJeG3CA7xD5Ykbsyopf9PrOISWjEvhTurW9zncQ8U/FJ+svR/Y13zHybbSt2e3E+G060EXWSwPX+Q4h/ul0hqjLpBqAJwjBSepD0edi83ftvmpMF5UlfeUZKaqTOtqar/AdQvzRjE8uoUxLDyBhuYm/SF72kO8cUlLOTbe2b+k7hPijGV+UZVIfIzigpaw5x9oDe365Yp5rmOg7S765vh5e+/03cX29kMtRs+P+jD7weJbc9kt6XnsOgOSYiYxt/gqxijdPervnP8PSv/9qYEWO0Qd8kpodZmx0nQCL/3oOvYtfonrbvRnz3hYAVtz3Byrqt6Jmh+nFe+PDd3tHW/P7fIcQP1R8UZVJNRJs4qz3HaUYns9NuO+wnnNn+M6Rb845XG8XsYpqXH8fr/3uTOoOPYlk/ZbEKmsAWHbnFcRHjCa130fftGyutwuLJ7FYnL7Vy1hwzReZfPp1YLFB12nJSlY98lfGfvBLLPzDd2k4+lvkertZ9reLaDz2LB9vf7hO7mhrvtx3CCk+beqMrkuISOkBbBdbMOOg2KNld+siM3t9JudyfZDrDw5pHSg95xyur4fg8pVvFktWYbHglM0Nn7OxdVosQa6vG+dywdctRuf//ZbUAccX/o0Wxi/Sre1b+Q4hxZfwHUA8yKSOAz7iO0axXZy8MDml+yoH9vYWCDGX62fBzDPoW76A2j2bqZy4IwBL2i9g3YuzSdZvwZhDThx02e75z7D0tl/St3IR9Ud89Y0i3Mg649UpFlz7ZUZOOZi+5QtwzlE5frvivNH8qwWuSre2H97R1qxNXxGiTZ1Rk0mlgGeAcb6j+HBB3zH3XNB3bNmcr7ihXNdqFt34E+oOO5mKhjQQFNiyOy6jcvz2jNzt8I0u27vkFZbcdh7jP/lzbIPrew+2zvUW3fAD6t7/BdZk76Bn0Vyq0lOpnfqBQry1QvtMR1vzb3yHkOLRps7o+QERLT2AL8Zv3HEE61b5zlEIsaqRVG25G+te/M/rX7NYnBE7v4e1z973jssm67fAktX0LH7pXdcJsPa5B6gYvx2ut4veFQtoOKqVtc/cS663K39vqHjOTre21/oOIcWj4ouSTGoKcLrvGD7FzTVcnPzlf979meHQv7aTXNdqAHK93XR1zCE5dhK9y+cDwT6+dc89SLJu8tuW7V3xGi7XD0Bf5yL6ls0jkWrcyDrfWN7197Fy9s2M2vcjuL5uXt9/6HLQ31fAd1sw44FQHp0jQ6N9fNHyS/R3zntjj03f1l596QU3KfQHNvSvXsaS9vOD0nE5anY6kOpt92bh775Jrnst4Eg2bs3Y9wWfd9Y+9yA9rz3H6AM/Rfe8J1n8wA0Qj2MWo+7wU4nXpOhZNPdt66zZbp/XX3PVf9oZueuhxJJVJBu2xvV1M/+q06nedi9iVSM9/SSG7Uvp1vYrdO++aNA+vqjIpI4kuKO6AK+6sQ/t333RPu/+TImQv3a0NX/IdwgpPG3qjILgzgvn+I5RSibZ0n2aYw884juHlJQj063th/gOIYWn4ouGk4EdfYcoNecmf52Kh3SnlBTMuenW9rI63UXeTsVX7jKpSuBbvmOUoirr3e47id+98+GOEjVTgaN8h5DCUvGVvxOBSb5DlKoT4n/bbQwrl/nOISXle74DSGGp+MpZJlUBtPqOUcpixujLK8573HcOKSl7pFvbj/QdQgpHxVfeTgC28B2i1O1lz+7fZC8+5zuHlBTN+sqYiq9cBUdyat/eJjAjfk3F2WV5NRcZsr3Tre0f9B1CCkPFV74+A6R9hwiLelu55yfid+qGtbKh7/sOIIWhE9jLUSZlwNPADr6jhEmvi780pfvq8T0kK31nkZJxcEdb812+Q0h+acZXng5HpbfZkta/1Y8TV93vO4eUlEhf27ZcqfjK02m+A4TVR+N3TxvHskW+c0jJOCrd2j7BdwjJLxVfucmktgCO8B0jrMyovbrinGd955CSkQBO8h1C8kvFV35OBuK+Q4TZLvbS/vvYU0/6ziEl4/Pp1vbI39WknKj4ykkmlQQ+5ztG2JlhV1Sc2+87h5SMScCHfYeQ/FHxlZdjiPDd1fMpZWubTorfqut4ynrab15GVHzlRbO9PDoz8Yetq+le6zuHlIRD0q3t2/gOIfmh4isXmVQjcLDvGOUkYbkJ5yUvedh3DikZx/kOIPmh4isfx6KDWvLuA7GH99nSFs7znUNKwsd8B5D8UPGVDw3KAjCj+trkz1/xnUNKwtR0a7suDFEGVHzlIJOaABzoO0a52ib22vSDY3P+6zuHlARt7iwDKr7y8FH0d1lQFycvrDRyOd85xDsVXxnQL8vyoMFYYDXWvdPXEn+613cO8W5KurV9F98hZHhUfGEXbOac7jtGFJwWv2WnWtZ0+s4h3n3EdwAZHhVf+B0OmO8QURAz13BJ8sJHfecQ797nO4AMj4ov/A73HSBKDohlZ+xgr8z1nUO82i/d2l7rO4QMnYov/A71HSBKzEjOrPj5Et85xKsE8F7fIWToVHxhlkntCuheYUU2wZbt/eHYvbN95xCvtKUlxFR84XaY7wBRdXbysro4/X2+c4g3GnshpuILN33q9KTS+rb5fuI3Or0hunZJt7ZP8h1ChkbFF1aZlPYzePaZ+D+m1tG51HcO8Ub710NKxRdeU4ARvkNEmRmpKyvO1Z3ao2sf3wFkaFR84TXNdwCBPez5Gbvb88/6ziFeaAyGlIovvDToSoAZ8asrzlnjO4d4sXu6tV23AgshFV947ek7gATG2qo9PhW//QHfOaToqoGdfYeQzafiC6NMKg7s7juGvOGsxHWTKujt9p1Dik5bXkJIxRdOuxB82pQSkbT+LdqSV2jWFz0qvhBS8YWTBlsJOjp2z7QJLH3Ndw4pKo3FEFLxhZPuB1aCzBh5TcXZL/jOIUU1xXcA2XwqvnDa1ncAGdyO9sqMGbHHn/CdQ4omlW5tr/MdQjaPii+ctvEdQAZnhl2aPN+Bc76zSNFoPIaMii+ctvYdQDZulK3b9dT4Lff5ziFFo+ILGRVf2GRSdUDKdwx5Z19P/HHbGrp0Yns0qPhCRsUXPhpkIRA3N/6XyYt1z75o0JgMGRVf+GiQhcRhsUf23cpem+c7hxScdj2EjIovfLb0HUA2jRlV1yXbVHzlL+07gGweFV/4jPUdQDbdVrFF+x0em/2o7xxSUDqdIWRUfOEzxncA2Ty/TP6qOkau33cOKZjR6dZ28x1CNp2KL3xUfCFTYz07fiMxS6c3lK8YMMp3CNl0Kr7wUfGF0MnxW3cZxepO3zmkYDQuQ0TFFz4aYCEUMzf20uQF2tdXvjQuQ0TFFz4aYCE1PfbkjJ3s5Rd955CC0LgMkYTvAL6Z2XeATwL9QA442Tn34EaeewLwD+fc/OIlfJvRxXyxrj7He65ZQ3c/9OXg2J0T/ODgKk68eR2zF/TjHOwwNsa1R1UzsuLN+/cferWfk/66DgAHZN5bydE7Jze6ToDj/7KW7MIcR+yQ4KeHBl/78d3d7NoY46idksV863lnRnJmRduyfbsv0bmY5aeo41KGJ9LFZ2bTgSOAPZ1z3WZWD1S8wyInAI8DPouvppgvVhmHf7aMYGSF0dvvOOCaNXxw+z7O/0AVoyqDovvq37v41UM9tB5Q+aZld22MMfukESRixoJVOXa/dA1H7pjY6DprkkZ1wnjs1JEc/ps1dHY51vY6Hny1n+++p3KweKEzzlbsdUzs7of/knvP3r6zSF4VdVzK8ER9U+cEYIlzrhvAObfEOTffzKaZ2b/N7BEz+7uZTTCzY4G9gN+Z2aNmVm1mh5rZHDPLmtnVZlYJYGZtZvakmT1mZr8Y+NqRZvbgwPPvMLNxQ8wcz8cb31Rm9vpMrjcHvf1g8HrpOedY1+sY7FjumqSRiAXf6eoDs3deZzIG6/ocOefo7Yd4DL7/r25+cFB5lN56bckr6xP09frOIXlV1HEpwxP14vsHsIWZPWtml5jZe80sCVwEHOucmwZcDfzEOXcDMBs43jk3lWDr3bXAcc65JoLZ86lmNhY4GpjinNsN+PHAa90D7Oec2wP4A3DmEDMXfYD15xxTL11N4zmrOHybBPtODjYUfPbmdYw/dzVPL83xxX0Hnyg/OK+PKZespunXq7m0uer1IhxsnTs3xGmoibHnZWs4cocEzy/LkXOw54Ty+p1SYX1bZxIzdXpDeSmvf6RlLtKbOp1zq81sGnAgcDAwi6CodgVut2CKEgcWDLL4jsBc59yzA/8/Ezgd+BXQBVxlZrcCtw58fzIwy8wmEGxOnTvE2EUfYPGY8egpI1nR5Th61loeX9TPro1xrvlwNf05xxf/XxezHu/ls3u8vfz2nZzgidNG8tTiflpuWscHt09QlbCNrvOCD1S9vuyR16/lsiOq+Mnd3fx3YT+Hb5Pg89PeaUt0eBwfv3PqOYkD/rvaKsprOhtRzsU1gw+RSBcfgHOuH7gLuMvMsgTl9YRzbvoQ19dnZvsAhwLHAl8ADiGYRZ7nnLvFzA4CMkONDINuWSy40VXGwekEf3u+j10bg/6Nx4yP75rk7Ht7Bi2+9XZuiDOywnh8UY69Jr7R3YOtE+Dmp3uZNiHG6h7HC8tz/PGjNbz/t2s4frckNcnwXyTj4erKebnxV+9WYxb+NyMAFXCq7wyyiSK9qdPMdjSz7Tf40lTgKaBh4MAXzCxpZlMGvr8KqB348zNA2sy2G/j/TwP/NrORQMo5dxvwFWD3ge+ngFcH/twyjNhFvfTV4jU5VnQFNxNf1+u4/cU+dhwb4/llOSDYx3fLM33sVP/2f0pzl+foywXLvrQix9NLcqRH26Dr3HD53n7HBQ/2cOb+lazrfaPl+3PQUwYX/nLgvjyuwaHSKyc53wFk00V9xjcSuMjMRgN9wPPAScDlwIVmliL4GV0APEGwT+9SM1sHTAc+C/zJzBLAw8ClBBesvdnMqgh+Z3914LUyA89dDvyTod/KpJ8i/r0tWO1ouWkt/TnIOfjYlCTNOyQ48Jq1rOx2OAe7j4/x6+ZqAG55ppfZ8/v54cFV3PNyH2339pCMQczgkuYq6mtiPLaw/23rPGKHN05VuPjhHlp2D2Z2u42LsbbP0fTr1fzPdglGV4W/K65OjbpvdSy2v+8ckldl8JEsOsw55zuDbI5MajUwwncMGZq1ZmumbzV5ZS7Y1yvl4/hsS/b3vkPIpon0ps6QWuk7gAxda8PY2Sq9sqRxGSIqvvBZ7juADM3LicS8f9VU7+s7hxSExmWIqPjCRwMspE4Z3zCPYN+vlB+NyxBR8YWPBlgI3VVT/egryeR+vnNIwWhchoiKL3w0wEImB7lvNIyt9p1DCkrjMkRUfOGjARYyF45J3dsVi+3oO4cUTFe2JdvlO4RsOhVf+KzwHUA2XWfMOq9OjdrFdw4pKI3JkFHxhc9rvgPIpvtqY8OjLrhwuZSvhb4DyOZR8YXPUC9uLUX2bDI596Gqyhm+c0jBveg7gGweFV/4aJCFxKnjG5YS3OZKypvGZMio+MLnJXRB3JL315E1sxclEnv5ziFFoeILGRVf2GQ6u4H5vmPIxvVC71n1Y7VfLzpUfCGj4gsnDbQS9vOxY+7rNRvq3TckfDQeQ0bFF04aaCVqaSy2ZFbtyKm+c0jR5Ah2P0iIqPjC6QXfAWRwXxjX8BTBfRwlGuZlW7LdvkPI5lHxhdOjvgPI2z1WWfHM45UVusFstGgshpCKL5we8R1A3u60cQ3rMNOYihaNxRDSIA2jTOcCYIHvGPKG39eOvL8zHte+vehR8YWQii+8NOBKRLfRdfbYMVv4ziFeaByGkIovvDTgSsT368c+2G822XcOKbr52Zasrp0bQiq+8FLxlYAF8fiC20bU6Aot0aQxGFIqvvDSoCsBp45vmIvZCN85xAuNwZBS8YVVpnM+ulODVw9UVT7+QjI53XcO8eYe3wFkaFR84XaH7wBR5cCdMa7BMDPfWcSLdaj4QkvFF263+w4QVZenRt23Jhab4juHeHOPrtgSXiq+cLsT3aKo6NaYrb5kTGo73znEK33oDDEVX5hlOpcBc3zHiJozG+sfyZmN851DvNJuhhBT8YWfPnkWUUci8fLd1VX7+c4hXi1G1+gMNRVf+OmTZxGdMr5xAWaVvnOIV//MtmSd7xAydCq+8LsHWOk7RBTcUVM959VkYl/fOcS723wHkOFR8YVdprMbuNl3jHLXD/2tDWNH+s4h3mm8lQEVX3mY5TtAuTu/bvS93bHY9r5ziHd/z7ZkO32HkOFR8ZWHfwArfIcoV52x2IrrRtXu6juHlAR9yCwDKr5ykOnsBW70HaNcndFY/5gzq/OdQ7xbB9ziO4QMn4qvfOiTaAE8XZF8YXZV5QzfOaQk3JZtya72HUKGT8VXPu4ElvgOUW5OHde4ArOE7xxSEv7oO4Dkh4qvXGQ6+9DAzKsbR454eEkiPs13DikJK4FbfYeQ/FDxlZdLfQcoFz3Q86P6ugbfOaRkXJdtya71HULyQ8VXTjKdWXSrlLz46di6+3vN0r5zSMm4xHcAyR8VX/nRAB2mJfHY4j/XjtjDdw4pGXdlW7JP+Q4h+aPiKz9/Bhb6DhFmp49reAazUb5zSMnQh8kyo+IrN5nOHuAq3zHC6j+VFU89WVGh0xdkvfnoHNmyo+IrT5cB/b5DhNEXxzX0YqZxIetdkW3J9vkOIfmlAV6OMp0vAzf5jhE2vxlVe//KeHw33zmkZHQTfIiUMqPiK18/9h0gTLrM1p1bN3pL3zmkpFyVbcku8B1C8k/FV64ynY+i6wpusu/W1z3UbzbJdw4pGT1Am+8QUhgqvvL2Q98BwuDVRHz+30fU7O07h5SUa7It2Vd8h5DCUPGVs0znI+hu0e/q1HGNHZjV+M4hJaMX+JnvEFI4Kr7yp1nfO7inuuqxuRVJnb4gG7ou25J9yXcIKRwVX7nLdD5IcKNaeQsH7muN9UnfOaSk9AE/9R1CCkvFFw3fAZzvEKXm16NT966NxXb2nUNKylXZluyLvkNIYZlz+n0YCZnUb4BP+Y5RKlabrZqx1eQuZxbqOzDkenLM/dlcXJ/D9TtG7T2KcUePY95V8+jq6MI5R+X4SiZ9bhLxqvibll374lrmXzP/9f9vPKqRUdNGbXSdAK9c+gpd87qonVrL+GPHA7DolkVUTapi1LTQX+VtJbB9tiW7yHcQKSzdYDM6vgV8BKj2HaQUfKOx/hFndpDvHMNlSSP9zTTxqjiuz/HiT1+ktqmWCZ+cQLw6KLoF1y9g2R3LaDjizR1fNamKbTPbYnGjd0Uvz3/veWqn1m50nbHKGLGKGNv/eHvmnjOX/rX95HpyrHthHY0favTx9vPtZyq9aNCmzqjIdM4DzvEdoxS8mEy8dE91VVkc0GJmr8/kXH8wQ8N4vfScc7ie4GtvFauMYfHgG673jedsbJ3Egxmmyzlcn4MYLPrLIhqPLovSmwuc7zuEFIdmfNHSBrQAW/kO4lPxSCgAAAv1SURBVNMp4xsXYlY2PwOXc7xw1gv0LOqh7tA6arYNzsyYd+U8Vj22iqqJVYz/+PhBl137wlpevepVepf2MvmkyW8U4UbWmahN8MJZLzB6xmh6FvbgnKM6XRYbEb6Sbcl2+w4hxaF9fFGTSX0EuMF3DF/+NqLmkW801k/znaMQ+tf08/JFLzPhUxOomlwFBAW24LcLqN66mjEHjtnosl3zu3j1ilfZ+ltbE6t4Y0PQYOtc76XzX2LiCRNZ/n/L6Xqli5FTRlJ3UF1h3lxh/S3bkv2g7xBSPNrUGTWZzj8T0dMb+qDvu/V1Kd85CiU+Is6InUewOrv69a9ZzEjtm2Ll7JXvuGzVxCpiVTG6X33zpGewdQKs/M9KqtJV5Lpz9CzuYcvTt2Tl7JXkunP5e0PF0Q182XcIKS4VXzSdDKx+12eVmXPrRt/bHYtt5ztHPvWt7KN/TXAHqlxPjtVPrKZifAXdC4MCc86xcs5KKiZUvG3ZnsU9wf47oGdJD90LuknWJwdf5wbLuz7H0n8speF/Gsj1vFF0r+/7C5dMtiX7rO8QUlzaxxdFmc4OMqlvAL/2HaVYVsRiy383qrbsbjnU19nHvCvm4XIOHKT2SVG7ey1zfzqX/q5+cFC1RRUTWyYCsHLOStbNXce4Y8ax5tk1LGlfEuzXi8HET08kUZug65Wut61z1NQ3TlVYeudSRu8/mlhljKotqnA9jue++xy1u9USHxHfWNRS9BA64CuStI8vqjIpA24HDvUdpRg+M6Hx7jlVVe/xnUNKRjewR7Yl+5TvIFJ82tQZVZlOB5wIrPIdpdCeqKh4bk5l5f6+c0hJOUulF10qvijLdL4EfMN3jEI7bXzDKsxCtQ1OCupB4Be+Q4g/Kr6oy3ReRrDJsyzdMHLEg8vi8T1955CS0Q18NtuS7fcdRPxR8QkEJ7Uv9B0i33qg5yf1dYOfuS1RdYY2cYqKTyDTuQD4BFBWn4J/VF93f18ZXaFFhu232Zbspb5DiH8qPglkOv8FfM93jHxZFI8vumnkCG3ilPUeJzh/VUTFJ2/SBtzqO0Q+nD6u4VnMan3nkJKwCjg225Jd6zuIlAYVn7whOMXhMwRXqg+t2VWVTz5dkdTpC7Le57It2Wd8h5DSoeKTN8t0Lgc+SnD0Wyh9qbGhH7NBbsQjEXRhtiX7R98hpLSo+OTtMp2PEBzpGbrL+lyTqr1vVTzW5DuHlIS/AV/zHUJKjy5ZJhuXSZ0J/Nx3jE21zmztfltN7syZTfCdRbybA7wn25KN3MXY5d1pxicbl+k8G7jEd4xN9e2GsQ+p9AR4GWhW6cnGqPjk3XwJuMV3iHczLxF/9Y6a6n195xDvVgAfzLZkF/gOIqVLxSfvLNPZT3By+0O+o7yTU8Y3voxZte8c4lUPcHS2Jfuk7yBS2lR88u4ynWuBI4HnfEcZzN3VVf99KZmc7juHeJUDTsi2ZO/yHURKn4pPNk2mcxFwECVWfjnIfb2xvtJ3DvEqR3Dh6et9B5FwUPHJpst0zqfEyu/i0al718ViO/nOId6sL73rfAeR8NDpDLL5MqmJwF3A9j5jrDJbuf9Wk7udWYPPHOKNSk+GRDM+2XwlMvP7WmP9HJVeZKn0ZMhUfDI0nsvv+WRy7v3VVTN8vLZ4p9KTYVHxydAF5bc/Hk51OGV8wxLMksV+XfFuHXCMSk+GQ8Unw5PpXAwcTBFPcr9tRM3shYnE3sV6PSkZi4GDsy3Zm30HkXBT8cnwBef5HQ1cXOiX6oO+79WPHVPo15GS8xwwPduSfdB3EAk/FZ/kR6YzR6bzC8CZFPCuDmfXjbmvJ2bbFmr9UpLuIyi9F3wHkfKg0xkk/zKp44CZQF5PLF8Wiy1975aTEpil8rleKWl/Bj6Vbcl2+Q4i5UMzPsm/TOcsYAZ5vpP7F8c1PKnSi4x+4FvAR1V6km+a8UnhZFJjgOuAI4a7qscrKp77xMRx22AWH34wKXELgY/ruptSKJrxSeFkOpcDHwK+TfAJfshOG9+wWqUXCf8H7KHSk0JS8UlhZTodmc6fAYcTfJLfbLNqRz64PB7fI7/BpAT9AjhE99KTQtOmTimeTGoCwUEvh2/qIj3QvW96i0V9ZlsULph4thj4vM7Pk2LRjE+KJ9O5gEzn+4CTgVWbtEj92AdUemXtT8AuKj0pJs34xI9MaivgSuCwjT1lYTy+8LAtJo7AbGTxgkmRLAZOz7Zk/+Q7iESPik/8yqROJti387ZyO2bS+Hufq6jYv/ihpMBuAE7LtmQX+w4i0aTiE/+C2d/lwPvWf+mhqsonThzfuAtm5i+Y5NlC4EvZluwffQeRaFPxSenIpI4BznOw5YytJj+xOhbb1XckyYs+4CIgk23JrvQdRkTFJ6Ulk6q+oXbEKT+oH/tjoMZ3HBm2O4AvZ1uyT/oOIrKeik9KUtPMpsnAT4FPAdrcGT5PA1/PtmTbfQcReSsVn5S0pplNewE/Bt7vO4tsknnAz4DLsy3ZPt9hRAaj4pNQaJrZtA/wfaDZdxYZ1MsEhXd1tiXb4zuMyDtR8UmoNM1smkZQgB/ynUWA4A4cPwOuzbZke32HEdkUKj4JpaaZTVOB7wJHAbp4dfE9C7QBv9EmTQkbXbJMQinbkn0025I9Ftga+AlDvAC2bJZ+4EaC8y13yrZkrxlO6ZnZv8zs/W/52hlmNtfMWjdzXRPN7IZNeN5tZjZ6c7NKedGMT8pC08ymJPAR4DTgQM9xys1rwBUEB6zMy9dKzewkYLpz7rMbfO0B4Ezn3N2DPD/hnNPsUoZNxSdlp2lm067AKcBxQL3nOGHVD/yT4HqqNxZi/52Z1RGc9jDZOddjZmngbuAsYJpz7gtmdi3QBewB3AtcDPwOGAHcDJzhnBs5sOytzrldzewEgn3ANcC2wI3OuTMHXrMD2Ms5t8TMPgN8HXDAY865T5vZkQSb0CuApcDxzjltTSgzCd8BRPIt25J9HPhC08ymM4BDCArwaGCM12ClL0dQPLOAPxf6WprOuWVm9hDwQYIS+zjwR4Ii2tBkYIZzrt/MbgV+6Zy73sxOeYfVTyUoy27gGTO7yDn3yvpvmtkUgoKbMVCCdQPfugfYzznnzOxzwJnA14b/bqWUqPikbA3sf/oH8I+mmU2nEOybOg74MDDKZ7YS4oD7CMruBg83gb2eoPDWF9+JQNNbnvMn51z/wJ+nExzQBPB7ggucD+ZO51wngJk9CWwFvLLB9w8ZWO8SCEp44OuTgVlmNoFg1jd3iO9LSpiKTyJhYFNdO9DeNLOpEtif4JZIhwN7Eq0DvRYQXErsduAOz3c8vxk438z2BGqcc4+Y2VuLb80Q1tu9wZ/72fTfdRcB5znnbjGzg4DMEF5bSpyKTyIn25LtJth/9U/g200zm+oIZgCHE5ThNh7jFcJq4N+8UXRPeM7zOufcajP7F3A1wezv3TxAcBDTLIIZ4lD9E7jRzM5zzi01s7qBWV8KeHXgOS3DWL+UMBWfRF62JbuM4B5xNwA0zWyaAEx7y2Oit4CbZx3wKPAI8J+B/z5Z4ufaXU9wmsSmFNkZwG/N7DvA34DOobygc+4JM/sJ8G8z6wfmACcQzPD+ZGbLCcpx66GsX0qbjuoU2QRNM5vGExTgVIIjBbcZeEzCz2bSFQT7n14ceDxBUHJPZVuy/e+0YJiZWQ2wbuDgk48Dn3DOfdh3LgkXFZ/IMDTNbKogOHBifRGOA0YTHEH61scogq0s8YGHEex/Wv9YS1Boywd5LANeYqDosi3Z5UV5gyXGzA4EfkXws1sB/K9z7nm/qSRsVHwiIhIpUTqSTURERMUnIiLRouITEZFIUfGJiEikqPhERCRSVHwiIhIpKj4REYkUFZ+IiESKik9ERCJFxSciIpGi4hMRkUhR8YmISKSo+EREJFJUfCIiEikqPhERiRQVn4iIRIqKT0REIkXFJyIikaLiExGRSFHxiYhIpKj4REQkUlR8IiISKSo+ERGJFBWfiIhEiopPREQiRcUnIiKRouITEZFIUfGJiEikqPhERCRSVHwiIhIpKj4REYkUFZ+IiESKik9ERCJFxSciIpGi4hMRkUj5/5oD6iXuHiWiAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "YoFNbD_IZsM4"
      },
      "outputs": [],
      "source": [
        "X = iris.drop('species', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "qb8dU73-ZsM5"
      },
      "outputs": [],
      "source": [
        "y = iris['species']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLTcESNkZsM6",
        "outputId": "fa679134-5d6b-464d-aa48-7af98f42bf2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "y.unique()\n",
        "print(sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "xARFEF7KZsM7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "encoder = LabelBinarizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "M2B8k074ZsM8"
      },
      "outputs": [],
      "source": [
        "y = encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "qW6tjlKfZsM-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "-RSKNmcmZsNA"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "6JKibH6FZsNB"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I1mN9VdZsNB",
        "outputId": "e3552509-a0f5-4e74-a466-afef44ed7753"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "scaler.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "n0jg9LN5ZsNC"
      },
      "outputs": [],
      "source": [
        "scaled_X_train = scaler.transform(X_train)\n",
        "scaled_X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "F_LESpybZsND"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPFBGV4oZsNE",
        "outputId": "c5f32300-2617-411f-b7c0-c46a567c2946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 3)                 15        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 95\n",
            "Trainable params: 95\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "4/4 [==============================] - 1s 67ms/step - loss: 1.0865 - accuracy: 0.3619 - val_loss: 1.0848 - val_accuracy: 0.2667\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0843 - accuracy: 0.3619 - val_loss: 1.0839 - val_accuracy: 0.2667\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0821 - accuracy: 0.3619 - val_loss: 1.0828 - val_accuracy: 0.2667\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0798 - accuracy: 0.3714 - val_loss: 1.0817 - val_accuracy: 0.2889\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0775 - accuracy: 0.3810 - val_loss: 1.0805 - val_accuracy: 0.2889\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0749 - accuracy: 0.3905 - val_loss: 1.0791 - val_accuracy: 0.3111\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0725 - accuracy: 0.3905 - val_loss: 1.0776 - val_accuracy: 0.3111\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0697 - accuracy: 0.3905 - val_loss: 1.0760 - val_accuracy: 0.3111\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0668 - accuracy: 0.4000 - val_loss: 1.0741 - val_accuracy: 0.3111\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0641 - accuracy: 0.4095 - val_loss: 1.0720 - val_accuracy: 0.3111\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0609 - accuracy: 0.4095 - val_loss: 1.0698 - val_accuracy: 0.3111\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0578 - accuracy: 0.4190 - val_loss: 1.0674 - val_accuracy: 0.3111\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0544 - accuracy: 0.4190 - val_loss: 1.0650 - val_accuracy: 0.3111\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0509 - accuracy: 0.4190 - val_loss: 1.0623 - val_accuracy: 0.3111\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0469 - accuracy: 0.4190 - val_loss: 1.0595 - val_accuracy: 0.3333\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0425 - accuracy: 0.4476 - val_loss: 1.0564 - val_accuracy: 0.3556\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0379 - accuracy: 0.4571 - val_loss: 1.0530 - val_accuracy: 0.3778\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0329 - accuracy: 0.4762 - val_loss: 1.0493 - val_accuracy: 0.3778\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0275 - accuracy: 0.5048 - val_loss: 1.0453 - val_accuracy: 0.4000\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0214 - accuracy: 0.5048 - val_loss: 1.0411 - val_accuracy: 0.4000\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.0155 - accuracy: 0.5238 - val_loss: 1.0369 - val_accuracy: 0.4000\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.0093 - accuracy: 0.5333 - val_loss: 1.0326 - val_accuracy: 0.4000\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0032 - accuracy: 0.5429 - val_loss: 1.0279 - val_accuracy: 0.4000\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9963 - accuracy: 0.5524 - val_loss: 1.0228 - val_accuracy: 0.4000\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9888 - accuracy: 0.5429 - val_loss: 1.0177 - val_accuracy: 0.4000\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9814 - accuracy: 0.5429 - val_loss: 1.0128 - val_accuracy: 0.4000\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9739 - accuracy: 0.5333 - val_loss: 1.0078 - val_accuracy: 0.4000\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9665 - accuracy: 0.5429 - val_loss: 1.0027 - val_accuracy: 0.4000\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9586 - accuracy: 0.5429 - val_loss: 0.9974 - val_accuracy: 0.4000\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9505 - accuracy: 0.5524 - val_loss: 0.9920 - val_accuracy: 0.4000\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9426 - accuracy: 0.5905 - val_loss: 0.9864 - val_accuracy: 0.4222\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.9347 - accuracy: 0.6190 - val_loss: 0.9808 - val_accuracy: 0.4444\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9268 - accuracy: 0.6286 - val_loss: 0.9750 - val_accuracy: 0.4444\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9184 - accuracy: 0.6381 - val_loss: 0.9687 - val_accuracy: 0.4444\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9102 - accuracy: 0.6381 - val_loss: 0.9626 - val_accuracy: 0.4667\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9022 - accuracy: 0.6476 - val_loss: 0.9565 - val_accuracy: 0.4667\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8935 - accuracy: 0.6571 - val_loss: 0.9503 - val_accuracy: 0.4667\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8850 - accuracy: 0.6667 - val_loss: 0.9444 - val_accuracy: 0.4667\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8768 - accuracy: 0.6762 - val_loss: 0.9385 - val_accuracy: 0.4889\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8680 - accuracy: 0.6762 - val_loss: 0.9324 - val_accuracy: 0.5111\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8599 - accuracy: 0.6762 - val_loss: 0.9262 - val_accuracy: 0.5333\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8514 - accuracy: 0.6762 - val_loss: 0.9198 - val_accuracy: 0.5556\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8430 - accuracy: 0.6857 - val_loss: 0.9138 - val_accuracy: 0.5556\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8347 - accuracy: 0.6857 - val_loss: 0.9080 - val_accuracy: 0.5556\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8262 - accuracy: 0.6857 - val_loss: 0.9020 - val_accuracy: 0.5556\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8183 - accuracy: 0.6857 - val_loss: 0.8962 - val_accuracy: 0.5556\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8101 - accuracy: 0.6952 - val_loss: 0.8897 - val_accuracy: 0.5556\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8025 - accuracy: 0.6952 - val_loss: 0.8829 - val_accuracy: 0.5556\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7945 - accuracy: 0.7048 - val_loss: 0.8765 - val_accuracy: 0.5556\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7866 - accuracy: 0.7048 - val_loss: 0.8700 - val_accuracy: 0.5556\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7790 - accuracy: 0.7048 - val_loss: 0.8633 - val_accuracy: 0.5556\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7714 - accuracy: 0.7048 - val_loss: 0.8576 - val_accuracy: 0.5556\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7639 - accuracy: 0.7048 - val_loss: 0.8513 - val_accuracy: 0.5556\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7564 - accuracy: 0.7143 - val_loss: 0.8451 - val_accuracy: 0.5556\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7490 - accuracy: 0.7143 - val_loss: 0.8391 - val_accuracy: 0.5556\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7417 - accuracy: 0.7143 - val_loss: 0.8325 - val_accuracy: 0.5556\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7347 - accuracy: 0.7143 - val_loss: 0.8258 - val_accuracy: 0.5556\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7276 - accuracy: 0.7143 - val_loss: 0.8192 - val_accuracy: 0.5556\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7205 - accuracy: 0.7143 - val_loss: 0.8124 - val_accuracy: 0.5556\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7133 - accuracy: 0.7143 - val_loss: 0.8067 - val_accuracy: 0.5556\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7066 - accuracy: 0.7143 - val_loss: 0.8018 - val_accuracy: 0.5556\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7000 - accuracy: 0.7143 - val_loss: 0.7953 - val_accuracy: 0.5556\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.7143 - val_loss: 0.7880 - val_accuracy: 0.5556\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6867 - accuracy: 0.7143 - val_loss: 0.7811 - val_accuracy: 0.5556\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6802 - accuracy: 0.7143 - val_loss: 0.7749 - val_accuracy: 0.5556\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6739 - accuracy: 0.7143 - val_loss: 0.7696 - val_accuracy: 0.5556\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6672 - accuracy: 0.7143 - val_loss: 0.7636 - val_accuracy: 0.5556\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6609 - accuracy: 0.7143 - val_loss: 0.7580 - val_accuracy: 0.5556\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6546 - accuracy: 0.7143 - val_loss: 0.7533 - val_accuracy: 0.5556\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6483 - accuracy: 0.7143 - val_loss: 0.7478 - val_accuracy: 0.5556\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6421 - accuracy: 0.7143 - val_loss: 0.7416 - val_accuracy: 0.5556\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6362 - accuracy: 0.7143 - val_loss: 0.7352 - val_accuracy: 0.5556\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6296 - accuracy: 0.7143 - val_loss: 0.7297 - val_accuracy: 0.5556\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6239 - accuracy: 0.7143 - val_loss: 0.7239 - val_accuracy: 0.5556\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6179 - accuracy: 0.7143 - val_loss: 0.7199 - val_accuracy: 0.5556\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6121 - accuracy: 0.7143 - val_loss: 0.7149 - val_accuracy: 0.5556\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6062 - accuracy: 0.7143 - val_loss: 0.7090 - val_accuracy: 0.5556\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6005 - accuracy: 0.7143 - val_loss: 0.7027 - val_accuracy: 0.5556\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5950 - accuracy: 0.7143 - val_loss: 0.6962 - val_accuracy: 0.5556\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5894 - accuracy: 0.7143 - val_loss: 0.6904 - val_accuracy: 0.5556\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5835 - accuracy: 0.7143 - val_loss: 0.6863 - val_accuracy: 0.5556\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5786 - accuracy: 0.7143 - val_loss: 0.6811 - val_accuracy: 0.5556\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5730 - accuracy: 0.7143 - val_loss: 0.6781 - val_accuracy: 0.5556\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5678 - accuracy: 0.7143 - val_loss: 0.6748 - val_accuracy: 0.5556\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5631 - accuracy: 0.7143 - val_loss: 0.6722 - val_accuracy: 0.5556\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5583 - accuracy: 0.7143 - val_loss: 0.6688 - val_accuracy: 0.5556\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5537 - accuracy: 0.7143 - val_loss: 0.6666 - val_accuracy: 0.5556\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5491 - accuracy: 0.7143 - val_loss: 0.6627 - val_accuracy: 0.5556\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5441 - accuracy: 0.7143 - val_loss: 0.6569 - val_accuracy: 0.5556\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5394 - accuracy: 0.7143 - val_loss: 0.6516 - val_accuracy: 0.5556\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5347 - accuracy: 0.7143 - val_loss: 0.6468 - val_accuracy: 0.5556\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5299 - accuracy: 0.7143 - val_loss: 0.6410 - val_accuracy: 0.5556\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5255 - accuracy: 0.7143 - val_loss: 0.6354 - val_accuracy: 0.5556\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5213 - accuracy: 0.7143 - val_loss: 0.6298 - val_accuracy: 0.5556\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5167 - accuracy: 0.7143 - val_loss: 0.6250 - val_accuracy: 0.5556\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5127 - accuracy: 0.7143 - val_loss: 0.6191 - val_accuracy: 0.5556\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5085 - accuracy: 0.7143 - val_loss: 0.6135 - val_accuracy: 0.5556\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5047 - accuracy: 0.7143 - val_loss: 0.6083 - val_accuracy: 0.5556\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5008 - accuracy: 0.7143 - val_loss: 0.6031 - val_accuracy: 0.5556\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4971 - accuracy: 0.7143 - val_loss: 0.5976 - val_accuracy: 0.5556\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4934 - accuracy: 0.7143 - val_loss: 0.5932 - val_accuracy: 0.5556\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4897 - accuracy: 0.7143 - val_loss: 0.5894 - val_accuracy: 0.5556\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4861 - accuracy: 0.7143 - val_loss: 0.5868 - val_accuracy: 0.5556\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4826 - accuracy: 0.7143 - val_loss: 0.5840 - val_accuracy: 0.5556\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4790 - accuracy: 0.7143 - val_loss: 0.5807 - val_accuracy: 0.5556\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4757 - accuracy: 0.7143 - val_loss: 0.5775 - val_accuracy: 0.5556\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4729 - accuracy: 0.7143 - val_loss: 0.5729 - val_accuracy: 0.5556\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4691 - accuracy: 0.7143 - val_loss: 0.5690 - val_accuracy: 0.5556\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4661 - accuracy: 0.7143 - val_loss: 0.5658 - val_accuracy: 0.5556\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4629 - accuracy: 0.7143 - val_loss: 0.5628 - val_accuracy: 0.5556\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4600 - accuracy: 0.7143 - val_loss: 0.5605 - val_accuracy: 0.5556\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4570 - accuracy: 0.7143 - val_loss: 0.5569 - val_accuracy: 0.5556\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4541 - accuracy: 0.7143 - val_loss: 0.5543 - val_accuracy: 0.5556\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4512 - accuracy: 0.7143 - val_loss: 0.5505 - val_accuracy: 0.5556\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4486 - accuracy: 0.7143 - val_loss: 0.5483 - val_accuracy: 0.5556\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4459 - accuracy: 0.7143 - val_loss: 0.5461 - val_accuracy: 0.5556\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4437 - accuracy: 0.7143 - val_loss: 0.5425 - val_accuracy: 0.5556\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4409 - accuracy: 0.7143 - val_loss: 0.5412 - val_accuracy: 0.5556\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4385 - accuracy: 0.7143 - val_loss: 0.5386 - val_accuracy: 0.5556\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4362 - accuracy: 0.7143 - val_loss: 0.5350 - val_accuracy: 0.5556\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4338 - accuracy: 0.7143 - val_loss: 0.5311 - val_accuracy: 0.5556\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4318 - accuracy: 0.7143 - val_loss: 0.5279 - val_accuracy: 0.5556\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4305 - accuracy: 0.7143 - val_loss: 0.5249 - val_accuracy: 0.5556\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4277 - accuracy: 0.7143 - val_loss: 0.5244 - val_accuracy: 0.5556\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4255 - accuracy: 0.7143 - val_loss: 0.5231 - val_accuracy: 0.5556\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4233 - accuracy: 0.7143 - val_loss: 0.5220 - val_accuracy: 0.5556\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4213 - accuracy: 0.7143 - val_loss: 0.5218 - val_accuracy: 0.5556\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4193 - accuracy: 0.7143 - val_loss: 0.5237 - val_accuracy: 0.5556\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4179 - accuracy: 0.7143 - val_loss: 0.5260 - val_accuracy: 0.5556\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4161 - accuracy: 0.7143 - val_loss: 0.5257 - val_accuracy: 0.5556\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4145 - accuracy: 0.7143 - val_loss: 0.5242 - val_accuracy: 0.5556\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4127 - accuracy: 0.7143 - val_loss: 0.5219 - val_accuracy: 0.5556\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4109 - accuracy: 0.7143 - val_loss: 0.5192 - val_accuracy: 0.5556\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4089 - accuracy: 0.7143 - val_loss: 0.5152 - val_accuracy: 0.5556\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4072 - accuracy: 0.7143 - val_loss: 0.5110 - val_accuracy: 0.5556\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4057 - accuracy: 0.7143 - val_loss: 0.5079 - val_accuracy: 0.5556\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4043 - accuracy: 0.7143 - val_loss: 0.5055 - val_accuracy: 0.5556\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4027 - accuracy: 0.7143 - val_loss: 0.5035 - val_accuracy: 0.5556\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4012 - accuracy: 0.7143 - val_loss: 0.5018 - val_accuracy: 0.5556\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3997 - accuracy: 0.7238 - val_loss: 0.4979 - val_accuracy: 0.5556\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3982 - accuracy: 0.7238 - val_loss: 0.4964 - val_accuracy: 0.5778\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3967 - accuracy: 0.7333 - val_loss: 0.4940 - val_accuracy: 0.5778\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3952 - accuracy: 0.7429 - val_loss: 0.4922 - val_accuracy: 0.5778\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3939 - accuracy: 0.7429 - val_loss: 0.4908 - val_accuracy: 0.5778\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3925 - accuracy: 0.7429 - val_loss: 0.4893 - val_accuracy: 0.5778\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3912 - accuracy: 0.7524 - val_loss: 0.4865 - val_accuracy: 0.6000\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3898 - accuracy: 0.7524 - val_loss: 0.4846 - val_accuracy: 0.6000\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3885 - accuracy: 0.7619 - val_loss: 0.4832 - val_accuracy: 0.6000\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3871 - accuracy: 0.7619 - val_loss: 0.4825 - val_accuracy: 0.6000\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3855 - accuracy: 0.7619 - val_loss: 0.4840 - val_accuracy: 0.6000\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3840 - accuracy: 0.7619 - val_loss: 0.4843 - val_accuracy: 0.5778\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3828 - accuracy: 0.7619 - val_loss: 0.4846 - val_accuracy: 0.5778\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3818 - accuracy: 0.7619 - val_loss: 0.4848 - val_accuracy: 0.5778\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3803 - accuracy: 0.7619 - val_loss: 0.4838 - val_accuracy: 0.5778\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3790 - accuracy: 0.7714 - val_loss: 0.4817 - val_accuracy: 0.5778\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3775 - accuracy: 0.7714 - val_loss: 0.4784 - val_accuracy: 0.6000\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3763 - accuracy: 0.7714 - val_loss: 0.4750 - val_accuracy: 0.6000\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3749 - accuracy: 0.7810 - val_loss: 0.4723 - val_accuracy: 0.6000\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3737 - accuracy: 0.7810 - val_loss: 0.4695 - val_accuracy: 0.6222\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3725 - accuracy: 0.7905 - val_loss: 0.4672 - val_accuracy: 0.6222\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3713 - accuracy: 0.7905 - val_loss: 0.4669 - val_accuracy: 0.6222\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3698 - accuracy: 0.7905 - val_loss: 0.4661 - val_accuracy: 0.6222\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3686 - accuracy: 0.7905 - val_loss: 0.4650 - val_accuracy: 0.6222\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3673 - accuracy: 0.7905 - val_loss: 0.4634 - val_accuracy: 0.6222\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3661 - accuracy: 0.7905 - val_loss: 0.4631 - val_accuracy: 0.6222\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3647 - accuracy: 0.7905 - val_loss: 0.4608 - val_accuracy: 0.6222\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3636 - accuracy: 0.7905 - val_loss: 0.4592 - val_accuracy: 0.6444\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3623 - accuracy: 0.7905 - val_loss: 0.4560 - val_accuracy: 0.6889\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3618 - accuracy: 0.8095 - val_loss: 0.4524 - val_accuracy: 0.6889\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3599 - accuracy: 0.8095 - val_loss: 0.4526 - val_accuracy: 0.6889\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3587 - accuracy: 0.8095 - val_loss: 0.4538 - val_accuracy: 0.6889\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3572 - accuracy: 0.7905 - val_loss: 0.4536 - val_accuracy: 0.6667\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3560 - accuracy: 0.7905 - val_loss: 0.4528 - val_accuracy: 0.6667\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3547 - accuracy: 0.7905 - val_loss: 0.4522 - val_accuracy: 0.6667\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3535 - accuracy: 0.7905 - val_loss: 0.4502 - val_accuracy: 0.6889\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3523 - accuracy: 0.8095 - val_loss: 0.4473 - val_accuracy: 0.6889\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3510 - accuracy: 0.8095 - val_loss: 0.4463 - val_accuracy: 0.6889\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3498 - accuracy: 0.8095 - val_loss: 0.4470 - val_accuracy: 0.6889\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3488 - accuracy: 0.8095 - val_loss: 0.4448 - val_accuracy: 0.6889\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3473 - accuracy: 0.8095 - val_loss: 0.4434 - val_accuracy: 0.6889\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3458 - accuracy: 0.8095 - val_loss: 0.4385 - val_accuracy: 0.7111\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3447 - accuracy: 0.8286 - val_loss: 0.4355 - val_accuracy: 0.7556\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3432 - accuracy: 0.8286 - val_loss: 0.4358 - val_accuracy: 0.7111\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3418 - accuracy: 0.8286 - val_loss: 0.4357 - val_accuracy: 0.7111\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3416 - accuracy: 0.8286 - val_loss: 0.4366 - val_accuracy: 0.7111\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3392 - accuracy: 0.8190 - val_loss: 0.4313 - val_accuracy: 0.7556\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3379 - accuracy: 0.8286 - val_loss: 0.4283 - val_accuracy: 0.7556\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3366 - accuracy: 0.8286 - val_loss: 0.4267 - val_accuracy: 0.7556\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3355 - accuracy: 0.8286 - val_loss: 0.4282 - val_accuracy: 0.7556\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3341 - accuracy: 0.8286 - val_loss: 0.4265 - val_accuracy: 0.7556\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3327 - accuracy: 0.8286 - val_loss: 0.4252 - val_accuracy: 0.7556\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3315 - accuracy: 0.8286 - val_loss: 0.4230 - val_accuracy: 0.7556\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3300 - accuracy: 0.8286 - val_loss: 0.4182 - val_accuracy: 0.7778\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3293 - accuracy: 0.8286 - val_loss: 0.4152 - val_accuracy: 0.8000\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3272 - accuracy: 0.8286 - val_loss: 0.4164 - val_accuracy: 0.7778\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3259 - accuracy: 0.8286 - val_loss: 0.4173 - val_accuracy: 0.7778\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3248 - accuracy: 0.8286 - val_loss: 0.4169 - val_accuracy: 0.7778\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3232 - accuracy: 0.8286 - val_loss: 0.4136 - val_accuracy: 0.7778\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3217 - accuracy: 0.8381 - val_loss: 0.4082 - val_accuracy: 0.8000\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3199 - accuracy: 0.8476 - val_loss: 0.4050 - val_accuracy: 0.8222\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3185 - accuracy: 0.8571 - val_loss: 0.4015 - val_accuracy: 0.8222\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3170 - accuracy: 0.8571 - val_loss: 0.3972 - val_accuracy: 0.8667\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3157 - accuracy: 0.8571 - val_loss: 0.3949 - val_accuracy: 0.8667\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3142 - accuracy: 0.8571 - val_loss: 0.3948 - val_accuracy: 0.8667\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3128 - accuracy: 0.8571 - val_loss: 0.3918 - val_accuracy: 0.8667\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3112 - accuracy: 0.8571 - val_loss: 0.3914 - val_accuracy: 0.8667\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3094 - accuracy: 0.8571 - val_loss: 0.3886 - val_accuracy: 0.8667\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3079 - accuracy: 0.8571 - val_loss: 0.3875 - val_accuracy: 0.8667\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3064 - accuracy: 0.8571 - val_loss: 0.3872 - val_accuracy: 0.8667\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3047 - accuracy: 0.8571 - val_loss: 0.3833 - val_accuracy: 0.8889\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3032 - accuracy: 0.8667 - val_loss: 0.3809 - val_accuracy: 0.8889\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3017 - accuracy: 0.8667 - val_loss: 0.3799 - val_accuracy: 0.8889\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2999 - accuracy: 0.8571 - val_loss: 0.3827 - val_accuracy: 0.8667\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2984 - accuracy: 0.8571 - val_loss: 0.3839 - val_accuracy: 0.8444\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2975 - accuracy: 0.8571 - val_loss: 0.3829 - val_accuracy: 0.8444\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2959 - accuracy: 0.8571 - val_loss: 0.3778 - val_accuracy: 0.8667\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2940 - accuracy: 0.8667 - val_loss: 0.3703 - val_accuracy: 0.8889\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2919 - accuracy: 0.8857 - val_loss: 0.3637 - val_accuracy: 0.9111\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2908 - accuracy: 0.9048 - val_loss: 0.3581 - val_accuracy: 0.9111\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2895 - accuracy: 0.9143 - val_loss: 0.3563 - val_accuracy: 0.9111\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2873 - accuracy: 0.9143 - val_loss: 0.3572 - val_accuracy: 0.9111\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2854 - accuracy: 0.9143 - val_loss: 0.3573 - val_accuracy: 0.9111\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2836 - accuracy: 0.8952 - val_loss: 0.3560 - val_accuracy: 0.9111\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2817 - accuracy: 0.8952 - val_loss: 0.3551 - val_accuracy: 0.9111\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2801 - accuracy: 0.8952 - val_loss: 0.3565 - val_accuracy: 0.8889\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2786 - accuracy: 0.8857 - val_loss: 0.3564 - val_accuracy: 0.8889\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2772 - accuracy: 0.8952 - val_loss: 0.3525 - val_accuracy: 0.9111\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2752 - accuracy: 0.8952 - val_loss: 0.3485 - val_accuracy: 0.9111\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2731 - accuracy: 0.9143 - val_loss: 0.3439 - val_accuracy: 0.9111\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2714 - accuracy: 0.9238 - val_loss: 0.3383 - val_accuracy: 0.9333\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2696 - accuracy: 0.9238 - val_loss: 0.3354 - val_accuracy: 0.9333\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2679 - accuracy: 0.9238 - val_loss: 0.3329 - val_accuracy: 0.9333\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2662 - accuracy: 0.9333 - val_loss: 0.3290 - val_accuracy: 0.9333\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2647 - accuracy: 0.9333 - val_loss: 0.3259 - val_accuracy: 0.9333\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2637 - accuracy: 0.9333 - val_loss: 0.3214 - val_accuracy: 0.9333\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2619 - accuracy: 0.9333 - val_loss: 0.3228 - val_accuracy: 0.9333\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2595 - accuracy: 0.9333 - val_loss: 0.3227 - val_accuracy: 0.9333\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2575 - accuracy: 0.9238 - val_loss: 0.3248 - val_accuracy: 0.9333\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2562 - accuracy: 0.9238 - val_loss: 0.3303 - val_accuracy: 0.9111\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2568 - accuracy: 0.9143 - val_loss: 0.3313 - val_accuracy: 0.9111\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2537 - accuracy: 0.9143 - val_loss: 0.3220 - val_accuracy: 0.9333\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2527 - accuracy: 0.9333 - val_loss: 0.3092 - val_accuracy: 0.9556\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2504 - accuracy: 0.9429 - val_loss: 0.3047 - val_accuracy: 0.9556\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2484 - accuracy: 0.9429 - val_loss: 0.3058 - val_accuracy: 0.9556\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2464 - accuracy: 0.9429 - val_loss: 0.3052 - val_accuracy: 0.9556\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2451 - accuracy: 0.9333 - val_loss: 0.3039 - val_accuracy: 0.9556\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2431 - accuracy: 0.9429 - val_loss: 0.2982 - val_accuracy: 0.9556\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2421 - accuracy: 0.9429 - val_loss: 0.2942 - val_accuracy: 0.9556\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2408 - accuracy: 0.9524 - val_loss: 0.2930 - val_accuracy: 0.9556\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2387 - accuracy: 0.9429 - val_loss: 0.2945 - val_accuracy: 0.9556\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2375 - accuracy: 0.9429 - val_loss: 0.2970 - val_accuracy: 0.9556\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2357 - accuracy: 0.9333 - val_loss: 0.2947 - val_accuracy: 0.9556\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2341 - accuracy: 0.9333 - val_loss: 0.2932 - val_accuracy: 0.9556\n",
            "Epoch 254/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2326 - accuracy: 0.9333 - val_loss: 0.2922 - val_accuracy: 0.9556\n",
            "Epoch 255/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2316 - accuracy: 0.9333 - val_loss: 0.2918 - val_accuracy: 0.9556\n",
            "Epoch 256/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2298 - accuracy: 0.9333 - val_loss: 0.2871 - val_accuracy: 0.9556\n",
            "Epoch 257/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2285 - accuracy: 0.9429 - val_loss: 0.2815 - val_accuracy: 0.9556\n",
            "Epoch 258/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2269 - accuracy: 0.9524 - val_loss: 0.2763 - val_accuracy: 0.9556\n",
            "Epoch 259/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2249 - accuracy: 0.9619 - val_loss: 0.2737 - val_accuracy: 0.9556\n",
            "Epoch 260/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2234 - accuracy: 0.9619 - val_loss: 0.2716 - val_accuracy: 0.9556\n",
            "Epoch 261/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2225 - accuracy: 0.9714 - val_loss: 0.2685 - val_accuracy: 0.9556\n",
            "Epoch 262/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2214 - accuracy: 0.9714 - val_loss: 0.2660 - val_accuracy: 0.9556\n",
            "Epoch 263/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2189 - accuracy: 0.9714 - val_loss: 0.2675 - val_accuracy: 0.9556\n",
            "Epoch 264/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2176 - accuracy: 0.9619 - val_loss: 0.2693 - val_accuracy: 0.9556\n",
            "Epoch 265/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2158 - accuracy: 0.9619 - val_loss: 0.2668 - val_accuracy: 0.9556\n",
            "Epoch 266/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2140 - accuracy: 0.9619 - val_loss: 0.2653 - val_accuracy: 0.9556\n",
            "Epoch 267/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2125 - accuracy: 0.9619 - val_loss: 0.2625 - val_accuracy: 0.9556\n",
            "Epoch 268/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2110 - accuracy: 0.9619 - val_loss: 0.2592 - val_accuracy: 0.9556\n",
            "Epoch 269/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2095 - accuracy: 0.9714 - val_loss: 0.2571 - val_accuracy: 0.9556\n",
            "Epoch 270/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2082 - accuracy: 0.9714 - val_loss: 0.2566 - val_accuracy: 0.9556\n",
            "Epoch 271/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2064 - accuracy: 0.9714 - val_loss: 0.2535 - val_accuracy: 0.9556\n",
            "Epoch 272/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2046 - accuracy: 0.9714 - val_loss: 0.2487 - val_accuracy: 0.9556\n",
            "Epoch 273/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2035 - accuracy: 0.9619 - val_loss: 0.2437 - val_accuracy: 0.9556\n",
            "Epoch 274/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2048 - accuracy: 0.9619 - val_loss: 0.2417 - val_accuracy: 0.9333\n",
            "Epoch 275/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2018 - accuracy: 0.9619 - val_loss: 0.2433 - val_accuracy: 0.9556\n",
            "Epoch 276/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1987 - accuracy: 0.9714 - val_loss: 0.2489 - val_accuracy: 0.9556\n",
            "Epoch 277/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1981 - accuracy: 0.9619 - val_loss: 0.2506 - val_accuracy: 0.9556\n",
            "Epoch 278/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1976 - accuracy: 0.9619 - val_loss: 0.2495 - val_accuracy: 0.9556\n",
            "Epoch 279/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1958 - accuracy: 0.9619 - val_loss: 0.2433 - val_accuracy: 0.9556\n",
            "Epoch 280/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1934 - accuracy: 0.9714 - val_loss: 0.2363 - val_accuracy: 0.9556\n",
            "Epoch 281/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1923 - accuracy: 0.9619 - val_loss: 0.2310 - val_accuracy: 0.9333\n",
            "Epoch 282/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1927 - accuracy: 0.9619 - val_loss: 0.2286 - val_accuracy: 0.9333\n",
            "Epoch 283/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1917 - accuracy: 0.9714 - val_loss: 0.2276 - val_accuracy: 0.9333\n",
            "Epoch 284/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1900 - accuracy: 0.9619 - val_loss: 0.2275 - val_accuracy: 0.9556\n",
            "Epoch 285/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1874 - accuracy: 0.9619 - val_loss: 0.2265 - val_accuracy: 0.9556\n",
            "Epoch 286/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1861 - accuracy: 0.9619 - val_loss: 0.2271 - val_accuracy: 0.9556\n",
            "Epoch 287/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1838 - accuracy: 0.9619 - val_loss: 0.2255 - val_accuracy: 0.9556\n",
            "Epoch 288/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1827 - accuracy: 0.9619 - val_loss: 0.2251 - val_accuracy: 0.9556\n",
            "Epoch 289/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1811 - accuracy: 0.9714 - val_loss: 0.2227 - val_accuracy: 0.9556\n",
            "Epoch 290/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1800 - accuracy: 0.9619 - val_loss: 0.2208 - val_accuracy: 0.9556\n",
            "Epoch 291/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1785 - accuracy: 0.9619 - val_loss: 0.2179 - val_accuracy: 0.9556\n",
            "Epoch 292/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1791 - accuracy: 0.9619 - val_loss: 0.2154 - val_accuracy: 0.9556\n",
            "Epoch 293/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1767 - accuracy: 0.9619 - val_loss: 0.2159 - val_accuracy: 0.9556\n",
            "Epoch 294/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1745 - accuracy: 0.9619 - val_loss: 0.2180 - val_accuracy: 0.9556\n",
            "Epoch 295/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1737 - accuracy: 0.9714 - val_loss: 0.2198 - val_accuracy: 0.9556\n",
            "Epoch 296/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1733 - accuracy: 0.9714 - val_loss: 0.2192 - val_accuracy: 0.9556\n",
            "Epoch 297/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1723 - accuracy: 0.9714 - val_loss: 0.2157 - val_accuracy: 0.9556\n",
            "Epoch 298/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1713 - accuracy: 0.9714 - val_loss: 0.2124 - val_accuracy: 0.9556\n",
            "Epoch 299/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1694 - accuracy: 0.9714 - val_loss: 0.2124 - val_accuracy: 0.9556\n",
            "Epoch 300/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1688 - accuracy: 0.9714 - val_loss: 0.2091 - val_accuracy: 0.9556\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbaf3ff9a90>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(patience=10)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "\n",
        "model.add(Dense(units=3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x=scaled_X_train, y=y_train, epochs=300, validation_data=(scaled_X_test, y_test), callbacks=[early_stop])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "metrics = pd.DataFrame(model.history.history)"
      ],
      "metadata": {
        "id": "NPWqEaaPZsNH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "QMXT_pXmZsNI",
        "outputId": "3d0880bb-2586-4800-d0bc-5ca1a629abdb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbaf3fc2d10>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "loss_history = pd.DataFrame(model.history.history)\n",
        "loss_history[['loss', 'val_loss']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56dllgbaZsNI",
        "outputId": "384726e6-1d23-45f5-df0f-af9ab1d28186"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20914530754089355, 0.9555555582046509]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "model.evaluate(scaled_X_test, y_test, verbose=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq8Q5Dd9ZsNJ",
        "outputId": "070b1565-d219-4ce5-cf5a-b923f7da946c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ],
      "source": [
        "epochs = len(loss_history)\n",
        "print(epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "8mKRGl9ZZsNK"
      },
      "outputs": [],
      "source": [
        "scaled_X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "b3UFKr59ZsNK"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "\n",
        "model.add(Dense(units=3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOQkLgiRZsNK",
        "outputId": "c70d0462-2cd0-4a81-bf66-52c20094d8f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 1.0974 - accuracy: 0.3533\n",
            "Epoch 2/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0972 - accuracy: 0.3667\n",
            "Epoch 3/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0969 - accuracy: 0.3533\n",
            "Epoch 4/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0967 - accuracy: 0.3467\n",
            "Epoch 5/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0965 - accuracy: 0.3400\n",
            "Epoch 6/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0963 - accuracy: 0.3400\n",
            "Epoch 7/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0959 - accuracy: 0.3533\n",
            "Epoch 8/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0957 - accuracy: 0.4533\n",
            "Epoch 9/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0953 - accuracy: 0.4800\n",
            "Epoch 10/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0949 - accuracy: 0.4533\n",
            "Epoch 11/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0945 - accuracy: 0.4533\n",
            "Epoch 12/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0941 - accuracy: 0.4600\n",
            "Epoch 13/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0935 - accuracy: 0.4400\n",
            "Epoch 14/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0929 - accuracy: 0.4200\n",
            "Epoch 15/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0922 - accuracy: 0.3933\n",
            "Epoch 16/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0915 - accuracy: 0.3867\n",
            "Epoch 17/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0907 - accuracy: 0.3933\n",
            "Epoch 18/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0896 - accuracy: 0.4267\n",
            "Epoch 19/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0884 - accuracy: 0.4200\n",
            "Epoch 20/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0871 - accuracy: 0.4467\n",
            "Epoch 21/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0855 - accuracy: 0.4600\n",
            "Epoch 22/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0837 - accuracy: 0.4800\n",
            "Epoch 23/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0814 - accuracy: 0.5067\n",
            "Epoch 24/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0787 - accuracy: 0.5333\n",
            "Epoch 25/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0757 - accuracy: 0.5733\n",
            "Epoch 26/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0723 - accuracy: 0.5733\n",
            "Epoch 27/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0684 - accuracy: 0.6000\n",
            "Epoch 28/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0642 - accuracy: 0.6000\n",
            "Epoch 29/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0597 - accuracy: 0.6000\n",
            "Epoch 30/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0549 - accuracy: 0.6000\n",
            "Epoch 31/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0497 - accuracy: 0.6000\n",
            "Epoch 32/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0442 - accuracy: 0.6000\n",
            "Epoch 33/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0386 - accuracy: 0.6000\n",
            "Epoch 34/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0323 - accuracy: 0.6067\n",
            "Epoch 35/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0261 - accuracy: 0.6200\n",
            "Epoch 36/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0192 - accuracy: 0.6400\n",
            "Epoch 37/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0122 - accuracy: 0.6400\n",
            "Epoch 38/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0049 - accuracy: 0.6400\n",
            "Epoch 39/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9974 - accuracy: 0.6400\n",
            "Epoch 40/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9897 - accuracy: 0.6400\n",
            "Epoch 41/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9819 - accuracy: 0.6400\n",
            "Epoch 42/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9740 - accuracy: 0.6400\n",
            "Epoch 43/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9658 - accuracy: 0.6400\n",
            "Epoch 44/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9576 - accuracy: 0.6400\n",
            "Epoch 45/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9494 - accuracy: 0.6400\n",
            "Epoch 46/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9411 - accuracy: 0.6467\n",
            "Epoch 47/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9328 - accuracy: 0.6533\n",
            "Epoch 48/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9244 - accuracy: 0.6533\n",
            "Epoch 49/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9161 - accuracy: 0.6533\n",
            "Epoch 50/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9078 - accuracy: 0.6533\n",
            "Epoch 51/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8997 - accuracy: 0.6533\n",
            "Epoch 52/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8917 - accuracy: 0.6533\n",
            "Epoch 53/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8839 - accuracy: 0.6533\n",
            "Epoch 54/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8760 - accuracy: 0.6533\n",
            "Epoch 55/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8689 - accuracy: 0.6533\n",
            "Epoch 56/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8610 - accuracy: 0.6600\n",
            "Epoch 57/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8539 - accuracy: 0.6667\n",
            "Epoch 58/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8471 - accuracy: 0.6667\n",
            "Epoch 59/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8400 - accuracy: 0.6467\n",
            "Epoch 60/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8337 - accuracy: 0.5800\n",
            "Epoch 61/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8271 - accuracy: 0.4200\n",
            "Epoch 62/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8210 - accuracy: 0.6467\n",
            "Epoch 63/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8150 - accuracy: 0.6667\n",
            "Epoch 64/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8093 - accuracy: 0.6667\n",
            "Epoch 65/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8040 - accuracy: 0.6667\n",
            "Epoch 66/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7988 - accuracy: 0.6667\n",
            "Epoch 67/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7940 - accuracy: 0.6667\n",
            "Epoch 68/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7893 - accuracy: 0.6667\n",
            "Epoch 69/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7845 - accuracy: 0.6667\n",
            "Epoch 70/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7802 - accuracy: 0.6667\n",
            "Epoch 71/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7760 - accuracy: 0.6667\n",
            "Epoch 72/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7720 - accuracy: 0.6667\n",
            "Epoch 73/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7682 - accuracy: 0.6667\n",
            "Epoch 74/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7644 - accuracy: 0.6667\n",
            "Epoch 75/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7608 - accuracy: 0.6667\n",
            "Epoch 76/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7574 - accuracy: 0.6667\n",
            "Epoch 77/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7541 - accuracy: 0.6667\n",
            "Epoch 78/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7509 - accuracy: 0.6667\n",
            "Epoch 79/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7477 - accuracy: 0.6667\n",
            "Epoch 80/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7446 - accuracy: 0.6667\n",
            "Epoch 81/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7416 - accuracy: 0.6667\n",
            "Epoch 82/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.6667\n",
            "Epoch 83/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.6667\n",
            "Epoch 84/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7330 - accuracy: 0.6667\n",
            "Epoch 85/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7305 - accuracy: 0.6667\n",
            "Epoch 86/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7276 - accuracy: 0.6667\n",
            "Epoch 87/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7248 - accuracy: 0.6667\n",
            "Epoch 88/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7224 - accuracy: 0.6667\n",
            "Epoch 89/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.7199 - accuracy: 0.6667\n",
            "Epoch 90/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.6667\n",
            "Epoch 91/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7149 - accuracy: 0.6667\n",
            "Epoch 92/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7124 - accuracy: 0.6667\n",
            "Epoch 93/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7101 - accuracy: 0.6667\n",
            "Epoch 94/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7077 - accuracy: 0.6667\n",
            "Epoch 95/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7053 - accuracy: 0.6667\n",
            "Epoch 96/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7031 - accuracy: 0.6667\n",
            "Epoch 97/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7007 - accuracy: 0.6667\n",
            "Epoch 98/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6985 - accuracy: 0.6667\n",
            "Epoch 99/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.6667\n",
            "Epoch 100/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.6667\n",
            "Epoch 101/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6917 - accuracy: 0.6667\n",
            "Epoch 102/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.6667\n",
            "Epoch 103/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.6667\n",
            "Epoch 104/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.6667\n",
            "Epoch 105/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.6667\n",
            "Epoch 106/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.6667\n",
            "Epoch 107/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.6667\n",
            "Epoch 108/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.6667\n",
            "Epoch 109/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6739 - accuracy: 0.6667\n",
            "Epoch 110/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.6667\n",
            "Epoch 111/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6667\n",
            "Epoch 112/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.6667\n",
            "Epoch 113/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.6667\n",
            "Epoch 114/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.6667\n",
            "Epoch 115/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.6667\n",
            "Epoch 116/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6594 - accuracy: 0.6667\n",
            "Epoch 117/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.6667\n",
            "Epoch 118/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6667\n",
            "Epoch 119/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.6667\n",
            "Epoch 120/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.6667\n",
            "Epoch 121/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6502 - accuracy: 0.6667\n",
            "Epoch 122/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.6667\n",
            "Epoch 123/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6466 - accuracy: 0.6667\n",
            "Epoch 124/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.6667\n",
            "Epoch 125/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.6667\n",
            "Epoch 126/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.6667\n",
            "Epoch 127/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6667\n",
            "Epoch 128/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.6667\n",
            "Epoch 129/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6667\n",
            "Epoch 130/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6667\n",
            "Epoch 131/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.6667\n",
            "Epoch 132/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.6667\n",
            "Epoch 133/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6297 - accuracy: 0.6667\n",
            "Epoch 134/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6282 - accuracy: 0.6667\n",
            "Epoch 135/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.6667\n",
            "Epoch 136/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.6667\n",
            "Epoch 137/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.6667\n",
            "Epoch 138/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.6667\n",
            "Epoch 139/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.6667\n",
            "Epoch 140/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.6667\n",
            "Epoch 141/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.6667\n",
            "Epoch 142/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.6667\n",
            "Epoch 143/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6667\n",
            "Epoch 144/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.6667\n",
            "Epoch 145/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.6667\n",
            "Epoch 146/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6667\n",
            "Epoch 147/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.6667\n",
            "Epoch 148/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6667\n",
            "Epoch 149/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.6667\n",
            "Epoch 150/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.6667\n",
            "Epoch 151/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.6667\n",
            "Epoch 152/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.6667\n",
            "Epoch 153/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.6733\n",
            "Epoch 154/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.6733\n",
            "Epoch 155/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.6733\n",
            "Epoch 156/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.6733\n",
            "Epoch 157/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.6733\n",
            "Epoch 158/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.6800\n",
            "Epoch 159/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.6733\n",
            "Epoch 160/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5879 - accuracy: 0.6800\n",
            "Epoch 161/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.6800\n",
            "Epoch 162/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.6867\n",
            "Epoch 163/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.6867\n",
            "Epoch 164/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5818 - accuracy: 0.6867\n",
            "Epoch 165/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.6867\n",
            "Epoch 166/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.6867\n",
            "Epoch 167/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.6867\n",
            "Epoch 168/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.6867\n",
            "Epoch 169/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5747 - accuracy: 0.6867\n",
            "Epoch 170/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.6867\n",
            "Epoch 171/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.6867\n",
            "Epoch 172/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.6867\n",
            "Epoch 173/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.6867\n",
            "Epoch 174/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5667 - accuracy: 0.6933\n",
            "Epoch 175/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.6933\n",
            "Epoch 176/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.6933\n",
            "Epoch 177/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5623 - accuracy: 0.6933\n",
            "Epoch 178/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.6933\n",
            "Epoch 179/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.7000\n",
            "Epoch 180/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.7000\n",
            "Epoch 181/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7000\n",
            "Epoch 182/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7000\n",
            "Epoch 183/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7067\n",
            "Epoch 184/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7067\n",
            "Epoch 185/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7067\n",
            "Epoch 186/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7067\n",
            "Epoch 187/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7133\n",
            "Epoch 188/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.7200\n",
            "Epoch 189/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7267\n",
            "Epoch 190/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5427 - accuracy: 0.7333\n",
            "Epoch 191/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7333\n",
            "Epoch 192/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7333\n",
            "Epoch 193/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7333\n",
            "Epoch 194/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7333\n",
            "Epoch 195/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7400\n",
            "Epoch 196/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7467\n",
            "Epoch 197/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7467\n",
            "Epoch 198/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.7467\n",
            "Epoch 199/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7333\n",
            "Epoch 200/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7467\n",
            "Epoch 201/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7467\n",
            "Epoch 202/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.7467\n",
            "Epoch 203/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7600\n",
            "Epoch 204/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7667\n",
            "Epoch 205/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7667\n",
            "Epoch 206/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7667\n",
            "Epoch 207/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7667\n",
            "Epoch 208/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7667\n",
            "Epoch 209/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7533\n",
            "Epoch 210/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7667\n",
            "Epoch 211/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7667\n",
            "Epoch 212/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7667\n",
            "Epoch 213/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7667\n",
            "Epoch 214/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7667\n",
            "Epoch 215/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7667\n",
            "Epoch 216/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7733\n",
            "Epoch 217/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7800\n",
            "Epoch 218/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7800\n",
            "Epoch 219/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7867\n",
            "Epoch 220/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7867\n",
            "Epoch 221/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7867\n",
            "Epoch 222/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7933\n",
            "Epoch 223/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7933\n",
            "Epoch 224/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7867\n",
            "Epoch 225/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7867\n",
            "Epoch 226/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7933\n",
            "Epoch 227/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7933\n",
            "Epoch 228/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.8000\n",
            "Epoch 229/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.8067\n",
            "Epoch 230/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.8067\n",
            "Epoch 231/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.8067\n",
            "Epoch 232/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.8067\n",
            "Epoch 233/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.8067\n",
            "Epoch 234/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4811 - accuracy: 0.8067\n",
            "Epoch 235/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.8067\n",
            "Epoch 236/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.8067\n",
            "Epoch 237/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.8067\n",
            "Epoch 238/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.8067\n",
            "Epoch 239/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.8200\n",
            "Epoch 240/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.8133\n",
            "Epoch 241/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.8133\n",
            "Epoch 242/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.8200\n",
            "Epoch 243/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.8133\n",
            "Epoch 244/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.8133\n",
            "Epoch 245/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.8133\n",
            "Epoch 246/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.8333\n",
            "Epoch 247/300\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.8467\n",
            "Epoch 248/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.8467\n",
            "Epoch 249/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.8467\n",
            "Epoch 250/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.8467\n",
            "Epoch 251/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.8467\n",
            "Epoch 252/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.8400\n",
            "Epoch 253/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.8333\n",
            "Epoch 254/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.8467\n",
            "Epoch 255/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.8533\n",
            "Epoch 256/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.8667\n",
            "Epoch 257/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8600\n",
            "Epoch 258/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.8533\n",
            "Epoch 259/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8533\n",
            "Epoch 260/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.8533\n",
            "Epoch 261/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.8667\n",
            "Epoch 262/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.8667\n",
            "Epoch 263/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.8600\n",
            "Epoch 264/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.8600\n",
            "Epoch 265/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.8733\n",
            "Epoch 266/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.8667\n",
            "Epoch 267/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.8667\n",
            "Epoch 268/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8667\n",
            "Epoch 269/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.8667\n",
            "Epoch 270/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.8667\n",
            "Epoch 271/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.8733\n",
            "Epoch 272/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.8800\n",
            "Epoch 273/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.8733\n",
            "Epoch 274/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.8733\n",
            "Epoch 275/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8600\n",
            "Epoch 276/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.8733\n",
            "Epoch 277/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8800\n",
            "Epoch 278/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8800\n",
            "Epoch 279/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8867\n",
            "Epoch 280/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8867\n",
            "Epoch 281/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8867\n",
            "Epoch 282/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8867\n",
            "Epoch 283/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8867\n",
            "Epoch 284/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8867\n",
            "Epoch 285/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.8933\n",
            "Epoch 286/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8867\n",
            "Epoch 287/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8867\n",
            "Epoch 288/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8867\n",
            "Epoch 289/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8867\n",
            "Epoch 290/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.9000\n",
            "Epoch 291/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.9067\n",
            "Epoch 292/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8933\n",
            "Epoch 293/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8933\n",
            "Epoch 294/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.9000\n",
            "Epoch 295/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.9067\n",
            "Epoch 296/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.9133\n",
            "Epoch 297/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.9133\n",
            "Epoch 298/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.9133\n",
            "Epoch 299/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.9200\n",
            "Epoch 300/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.9200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb8264ed90>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "model.fit(scaled_X, y, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "DSMnvRxIZsNL"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(scaler, 'iris_classifier.pkl')\n",
        "model.save(\"iris_classifier.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "xGRRQPRjZsNL"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "iris_classifier = load_model('iris_classifier.h5')\n",
        "flower_scaler = joblib.load(\"iris_classifier.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "ZnBLZzA-ZsNM"
      },
      "outputs": [],
      "source": [
        "flower_test = {\"sepal_length\": 5.6,\n",
        "                  \"sepal_width\": 2.9,\n",
        "                  \"petal_length\": 4,\n",
        "                  \"petal_width\": 1.2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFROX5MNZsNN",
        "outputId": "0e6b73ae-bccd-4bd9-e7c6-0a28f47174e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['versicolor']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_iris_prediction(model, scaler, request):\n",
        "    sepal_length = request[\"sepal_length\"]\n",
        "    sepal_width = request[\"sepal_width\"]\n",
        "    petal_length = request[\"petal_length\"]\n",
        "    petal_width = request[\"petal_width\"]\n",
        "    \n",
        "    flower = [[sepal_length, sepal_width, petal_length, petal_width]]\n",
        "    flower = scaler.transform(flower)\n",
        "    \n",
        "    iris_classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
        "    \n",
        "    prediction = model.predict(flower)\n",
        "    class_index = np.argmax(prediction, axis=1)\n",
        "    print(iris_classes[class_index])\n",
        "\n",
        "get_iris_prediction(iris_classifier, flower_scaler, flower_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion matrix"
      ],
      "metadata": {
        "id": "jECdIYYpaIu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot non-normalized confusion matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "class_names = iris['species']\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "titles_options = [\n",
        "    (\"Confusion matrix, without normalization\", None),\n",
        "    (\"Normalized confusion matrix\", \"true\"),\n",
        "]\n",
        "for title, normalize in titles_options:\n",
        "    disp = ConfusionMatrixDisplay.from_estimator(\n",
        "        model,\n",
        "        X_test,\n",
        "        y_test,\n",
        "        display_labels=class_names,\n",
        "        # cmap=plt.cm.Blues,\n",
        "        # normalize=normalize,\n",
        "    )\n",
        "    disp.ax_.set_title(title)\n",
        "\n",
        "    print(title)\n",
        "    print(disp.confusion_matrix)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "n4WGdiBPaLzN",
        "outputId": "01485e34-3714-4b02-bf03-64b959aac044"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-3e68fb1730c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mdisplay_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# cmap=plt.cm.Blues,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# normalize=normalize,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_plot/confusion_matrix.py\u001b[0m in \u001b[0;36mfrom_estimator\u001b[0;34m(cls, estimator, X, y, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mcheck_matplotlib_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{method_name} only supports classifiers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: ConfusionMatrixDisplay.from_estimator only supports classifiers"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "iris_classifier_implementation.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}