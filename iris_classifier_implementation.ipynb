{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "4c4oWGlvZsMy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WjulnLXZsM3",
        "outputId": "f5f54db7-a255-4358-a591-8e21ed674990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "# load csv data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "\n",
        "flowersPath = Path('/content/gdrive/Othercomputers/DavideLaptop/Desktop/IrisClassification')\n",
        "iris = pd.read_csv(Path('/content/gdrive/Othercomputers/DavideLaptop/Desktop/IrisClassification/iris.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "YoFNbD_IZsM4"
      },
      "outputs": [],
      "source": [
        "X = iris.drop('species', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "qb8dU73-ZsM5"
      },
      "outputs": [],
      "source": [
        "y = iris['species']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLTcESNkZsM6",
        "outputId": "181ad5fe-3539-4029-ce40-eea25dc017d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "y.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "xARFEF7KZsM7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "encoder = LabelBinarizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "M2B8k074ZsM8"
      },
      "outputs": [],
      "source": [
        "y = encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "qW6tjlKfZsM-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "-RSKNmcmZsNA"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "6JKibH6FZsNB"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I1mN9VdZsNB",
        "outputId": "2c223a82-af97-479b-bae3-9dcfc3a627b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "scaler.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "n0jg9LN5ZsNC"
      },
      "outputs": [],
      "source": [
        "scaled_X_train = scaler.transform(X_train)\n",
        "scaled_X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "F_LESpybZsND"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPFBGV4oZsNE",
        "outputId": "af6d5947-951d-4e1b-ebbe-533f5f6bae82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 3)                 15        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 95\n",
            "Trainable params: 95\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "4/4 [==============================] - 1s 71ms/step - loss: 1.0973 - accuracy: 0.3167 - val_loss: 1.1014 - val_accuracy: 0.3000\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0951 - accuracy: 0.3583 - val_loss: 1.0987 - val_accuracy: 0.2667\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.0934 - accuracy: 0.3500 - val_loss: 1.0975 - val_accuracy: 0.2667\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0927 - accuracy: 0.3500 - val_loss: 1.0967 - val_accuracy: 0.2667\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0923 - accuracy: 0.3500 - val_loss: 1.0962 - val_accuracy: 0.2667\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0918 - accuracy: 0.3500 - val_loss: 1.0958 - val_accuracy: 0.2667\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0911 - accuracy: 0.3500 - val_loss: 1.0957 - val_accuracy: 0.2667\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0898 - accuracy: 0.3500 - val_loss: 1.0952 - val_accuracy: 0.2667\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0883 - accuracy: 0.3500 - val_loss: 1.0946 - val_accuracy: 0.2667\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0868 - accuracy: 0.3500 - val_loss: 1.0944 - val_accuracy: 0.2667\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0847 - accuracy: 0.3500 - val_loss: 1.0934 - val_accuracy: 0.2667\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0830 - accuracy: 0.3500 - val_loss: 1.0922 - val_accuracy: 0.2667\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0805 - accuracy: 0.3500 - val_loss: 1.0903 - val_accuracy: 0.2667\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0779 - accuracy: 0.3500 - val_loss: 1.0876 - val_accuracy: 0.2667\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0745 - accuracy: 0.3500 - val_loss: 1.0845 - val_accuracy: 0.2667\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0710 - accuracy: 0.3583 - val_loss: 1.0809 - val_accuracy: 0.4000\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0669 - accuracy: 0.6250 - val_loss: 1.0763 - val_accuracy: 0.5000\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0619 - accuracy: 0.6750 - val_loss: 1.0708 - val_accuracy: 0.5667\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0561 - accuracy: 0.6833 - val_loss: 1.0648 - val_accuracy: 0.6000\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0498 - accuracy: 0.6833 - val_loss: 1.0577 - val_accuracy: 0.6000\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0425 - accuracy: 0.6833 - val_loss: 1.0499 - val_accuracy: 0.6000\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0343 - accuracy: 0.6833 - val_loss: 1.0409 - val_accuracy: 0.6000\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0256 - accuracy: 0.6833 - val_loss: 1.0308 - val_accuracy: 0.6000\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0156 - accuracy: 0.6833 - val_loss: 1.0198 - val_accuracy: 0.7333\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0044 - accuracy: 0.7500 - val_loss: 1.0084 - val_accuracy: 0.7333\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9938 - accuracy: 0.7500 - val_loss: 0.9961 - val_accuracy: 0.7333\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9816 - accuracy: 0.7667 - val_loss: 0.9838 - val_accuracy: 0.7333\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9691 - accuracy: 0.7917 - val_loss: 0.9718 - val_accuracy: 0.7333\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9567 - accuracy: 0.7750 - val_loss: 0.9595 - val_accuracy: 0.7333\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9440 - accuracy: 0.7583 - val_loss: 0.9462 - val_accuracy: 0.7333\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9299 - accuracy: 0.7750 - val_loss: 0.9324 - val_accuracy: 0.7000\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9173 - accuracy: 0.7667 - val_loss: 0.9188 - val_accuracy: 0.7333\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9029 - accuracy: 0.7500 - val_loss: 0.9049 - val_accuracy: 0.7333\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8898 - accuracy: 0.7417 - val_loss: 0.8905 - val_accuracy: 0.7667\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8752 - accuracy: 0.7667 - val_loss: 0.8766 - val_accuracy: 0.7667\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8622 - accuracy: 0.7583 - val_loss: 0.8629 - val_accuracy: 0.7667\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8497 - accuracy: 0.7500 - val_loss: 0.8493 - val_accuracy: 0.8000\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8364 - accuracy: 0.7417 - val_loss: 0.8362 - val_accuracy: 0.8333\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8238 - accuracy: 0.7417 - val_loss: 0.8239 - val_accuracy: 0.8333\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8125 - accuracy: 0.7333 - val_loss: 0.8121 - val_accuracy: 0.8333\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8010 - accuracy: 0.7333 - val_loss: 0.8009 - val_accuracy: 0.8000\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7906 - accuracy: 0.7500 - val_loss: 0.7906 - val_accuracy: 0.8000\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7806 - accuracy: 0.7583 - val_loss: 0.7813 - val_accuracy: 0.8000\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7717 - accuracy: 0.7333 - val_loss: 0.7726 - val_accuracy: 0.7667\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7635 - accuracy: 0.7250 - val_loss: 0.7645 - val_accuracy: 0.7667\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7559 - accuracy: 0.7167 - val_loss: 0.7570 - val_accuracy: 0.7667\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7485 - accuracy: 0.7083 - val_loss: 0.7500 - val_accuracy: 0.7667\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7418 - accuracy: 0.7000 - val_loss: 0.7433 - val_accuracy: 0.7333\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7355 - accuracy: 0.7000 - val_loss: 0.7371 - val_accuracy: 0.7333\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7294 - accuracy: 0.7000 - val_loss: 0.7312 - val_accuracy: 0.7333\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7240 - accuracy: 0.7000 - val_loss: 0.7256 - val_accuracy: 0.7333\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7187 - accuracy: 0.7000 - val_loss: 0.7205 - val_accuracy: 0.7333\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7140 - accuracy: 0.6917 - val_loss: 0.7154 - val_accuracy: 0.7333\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7092 - accuracy: 0.6917 - val_loss: 0.7108 - val_accuracy: 0.7333\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7048 - accuracy: 0.7000 - val_loss: 0.7064 - val_accuracy: 0.7333\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7006 - accuracy: 0.7083 - val_loss: 0.7021 - val_accuracy: 0.7333\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6967 - accuracy: 0.7083 - val_loss: 0.6982 - val_accuracy: 0.7333\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6928 - accuracy: 0.7083 - val_loss: 0.6943 - val_accuracy: 0.7667\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6892 - accuracy: 0.7083 - val_loss: 0.6905 - val_accuracy: 0.7667\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6857 - accuracy: 0.7083 - val_loss: 0.6871 - val_accuracy: 0.7667\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.7083 - val_loss: 0.6837 - val_accuracy: 0.7667\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6791 - accuracy: 0.7083 - val_loss: 0.6803 - val_accuracy: 0.7667\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6758 - accuracy: 0.7083 - val_loss: 0.6772 - val_accuracy: 0.7667\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6728 - accuracy: 0.7083 - val_loss: 0.6740 - val_accuracy: 0.7667\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6696 - accuracy: 0.7083 - val_loss: 0.6708 - val_accuracy: 0.7667\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6665 - accuracy: 0.7083 - val_loss: 0.6675 - val_accuracy: 0.7667\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6634 - accuracy: 0.7083 - val_loss: 0.6645 - val_accuracy: 0.7667\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6603 - accuracy: 0.7083 - val_loss: 0.6615 - val_accuracy: 0.7667\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6573 - accuracy: 0.7083 - val_loss: 0.6581 - val_accuracy: 0.7667\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6542 - accuracy: 0.7083 - val_loss: 0.6547 - val_accuracy: 0.7667\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6511 - accuracy: 0.7333 - val_loss: 0.6515 - val_accuracy: 0.7333\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6480 - accuracy: 0.7500 - val_loss: 0.6485 - val_accuracy: 0.7667\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6451 - accuracy: 0.7583 - val_loss: 0.6455 - val_accuracy: 0.7667\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6420 - accuracy: 0.7667 - val_loss: 0.6425 - val_accuracy: 0.7667\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6391 - accuracy: 0.7667 - val_loss: 0.6395 - val_accuracy: 0.7667\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6360 - accuracy: 0.7833 - val_loss: 0.6365 - val_accuracy: 0.7667\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6330 - accuracy: 0.8000 - val_loss: 0.6337 - val_accuracy: 0.7667\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6296 - accuracy: 0.8000 - val_loss: 0.6307 - val_accuracy: 0.8000\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6266 - accuracy: 0.8000 - val_loss: 0.6280 - val_accuracy: 0.8000\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6233 - accuracy: 0.8250 - val_loss: 0.6252 - val_accuracy: 0.8667\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6201 - accuracy: 0.8250 - val_loss: 0.6225 - val_accuracy: 0.9000\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6169 - accuracy: 0.8250 - val_loss: 0.6195 - val_accuracy: 0.9000\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6137 - accuracy: 0.8083 - val_loss: 0.6172 - val_accuracy: 0.8667\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6102 - accuracy: 0.8167 - val_loss: 0.6139 - val_accuracy: 0.8667\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6070 - accuracy: 0.8250 - val_loss: 0.6109 - val_accuracy: 0.8667\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6037 - accuracy: 0.8417 - val_loss: 0.6080 - val_accuracy: 0.8333\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6001 - accuracy: 0.8333 - val_loss: 0.6046 - val_accuracy: 0.8333\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5967 - accuracy: 0.8333 - val_loss: 0.6011 - val_accuracy: 0.8667\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5929 - accuracy: 0.8417 - val_loss: 0.5980 - val_accuracy: 0.8333\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5894 - accuracy: 0.8417 - val_loss: 0.5944 - val_accuracy: 0.8333\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5854 - accuracy: 0.8500 - val_loss: 0.5906 - val_accuracy: 0.8333\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5813 - accuracy: 0.8417 - val_loss: 0.5875 - val_accuracy: 0.8333\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5772 - accuracy: 0.8500 - val_loss: 0.5840 - val_accuracy: 0.8333\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5729 - accuracy: 0.8583 - val_loss: 0.5791 - val_accuracy: 0.8667\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5685 - accuracy: 0.8500 - val_loss: 0.5753 - val_accuracy: 0.8333\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5640 - accuracy: 0.8583 - val_loss: 0.5713 - val_accuracy: 0.8333\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5596 - accuracy: 0.8500 - val_loss: 0.5677 - val_accuracy: 0.8333\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5549 - accuracy: 0.8583 - val_loss: 0.5635 - val_accuracy: 0.8333\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5510 - accuracy: 0.8583 - val_loss: 0.5599 - val_accuracy: 0.8333\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5457 - accuracy: 0.8583 - val_loss: 0.5552 - val_accuracy: 0.8333\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5410 - accuracy: 0.8667 - val_loss: 0.5507 - val_accuracy: 0.8667\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5363 - accuracy: 0.8667 - val_loss: 0.5466 - val_accuracy: 0.8333\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5313 - accuracy: 0.8667 - val_loss: 0.5425 - val_accuracy: 0.8333\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5263 - accuracy: 0.8583 - val_loss: 0.5384 - val_accuracy: 0.8333\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5209 - accuracy: 0.8583 - val_loss: 0.5338 - val_accuracy: 0.8333\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5159 - accuracy: 0.8583 - val_loss: 0.5288 - val_accuracy: 0.8333\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5105 - accuracy: 0.8583 - val_loss: 0.5245 - val_accuracy: 0.8333\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5048 - accuracy: 0.8667 - val_loss: 0.5201 - val_accuracy: 0.8333\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4992 - accuracy: 0.8833 - val_loss: 0.5160 - val_accuracy: 0.8333\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4936 - accuracy: 0.8917 - val_loss: 0.5113 - val_accuracy: 0.8333\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4878 - accuracy: 0.8917 - val_loss: 0.5066 - val_accuracy: 0.8667\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4824 - accuracy: 0.8833 - val_loss: 0.5024 - val_accuracy: 0.8667\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4761 - accuracy: 0.9000 - val_loss: 0.4967 - val_accuracy: 0.8667\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4707 - accuracy: 0.8917 - val_loss: 0.4913 - val_accuracy: 0.8333\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4637 - accuracy: 0.8917 - val_loss: 0.4865 - val_accuracy: 0.8667\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4578 - accuracy: 0.9000 - val_loss: 0.4821 - val_accuracy: 0.8667\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4522 - accuracy: 0.9083 - val_loss: 0.4777 - val_accuracy: 0.8667\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4455 - accuracy: 0.9000 - val_loss: 0.4716 - val_accuracy: 0.8667\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4391 - accuracy: 0.9000 - val_loss: 0.4661 - val_accuracy: 0.8667\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4330 - accuracy: 0.8917 - val_loss: 0.4609 - val_accuracy: 0.8667\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4271 - accuracy: 0.9083 - val_loss: 0.4561 - val_accuracy: 0.8667\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4202 - accuracy: 0.9083 - val_loss: 0.4508 - val_accuracy: 0.8667\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4137 - accuracy: 0.9083 - val_loss: 0.4451 - val_accuracy: 0.8667\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4077 - accuracy: 0.9000 - val_loss: 0.4396 - val_accuracy: 0.8667\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4017 - accuracy: 0.9083 - val_loss: 0.4337 - val_accuracy: 0.8667\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3961 - accuracy: 0.9000 - val_loss: 0.4283 - val_accuracy: 0.8667\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3896 - accuracy: 0.9083 - val_loss: 0.4234 - val_accuracy: 0.8667\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3834 - accuracy: 0.9083 - val_loss: 0.4184 - val_accuracy: 0.8667\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3772 - accuracy: 0.9000 - val_loss: 0.4127 - val_accuracy: 0.8667\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3717 - accuracy: 0.9083 - val_loss: 0.4076 - val_accuracy: 0.8667\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3654 - accuracy: 0.9083 - val_loss: 0.4021 - val_accuracy: 0.8667\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3602 - accuracy: 0.9083 - val_loss: 0.3972 - val_accuracy: 0.8667\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3539 - accuracy: 0.9083 - val_loss: 0.3917 - val_accuracy: 0.8667\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3484 - accuracy: 0.9083 - val_loss: 0.3868 - val_accuracy: 0.8667\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3426 - accuracy: 0.9083 - val_loss: 0.3819 - val_accuracy: 0.8667\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3374 - accuracy: 0.9083 - val_loss: 0.3773 - val_accuracy: 0.8667\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3318 - accuracy: 0.9083 - val_loss: 0.3728 - val_accuracy: 0.8667\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3262 - accuracy: 0.9083 - val_loss: 0.3682 - val_accuracy: 0.8667\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3212 - accuracy: 0.9083 - val_loss: 0.3638 - val_accuracy: 0.8667\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3160 - accuracy: 0.9083 - val_loss: 0.3589 - val_accuracy: 0.8667\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3110 - accuracy: 0.9083 - val_loss: 0.3540 - val_accuracy: 0.8667\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3061 - accuracy: 0.9167 - val_loss: 0.3488 - val_accuracy: 0.8667\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3013 - accuracy: 0.9167 - val_loss: 0.3442 - val_accuracy: 0.9000\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2957 - accuracy: 0.9083 - val_loss: 0.3404 - val_accuracy: 0.8667\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2939 - accuracy: 0.9083 - val_loss: 0.3374 - val_accuracy: 0.8667\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2876 - accuracy: 0.9083 - val_loss: 0.3319 - val_accuracy: 0.9000\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2823 - accuracy: 0.9167 - val_loss: 0.3276 - val_accuracy: 0.9000\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2791 - accuracy: 0.9083 - val_loss: 0.3235 - val_accuracy: 0.9000\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2749 - accuracy: 0.9083 - val_loss: 0.3195 - val_accuracy: 0.9000\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2701 - accuracy: 0.9167 - val_loss: 0.3158 - val_accuracy: 0.9000\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2662 - accuracy: 0.9167 - val_loss: 0.3123 - val_accuracy: 0.9000\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2626 - accuracy: 0.9167 - val_loss: 0.3086 - val_accuracy: 0.9000\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2585 - accuracy: 0.9167 - val_loss: 0.3047 - val_accuracy: 0.9000\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2550 - accuracy: 0.9250 - val_loss: 0.3009 - val_accuracy: 0.9000\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2513 - accuracy: 0.9250 - val_loss: 0.2973 - val_accuracy: 0.9000\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2480 - accuracy: 0.9167 - val_loss: 0.2940 - val_accuracy: 0.9000\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2445 - accuracy: 0.9167 - val_loss: 0.2909 - val_accuracy: 0.9000\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2410 - accuracy: 0.9250 - val_loss: 0.2877 - val_accuracy: 0.9000\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2379 - accuracy: 0.9250 - val_loss: 0.2846 - val_accuracy: 0.9000\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2347 - accuracy: 0.9250 - val_loss: 0.2815 - val_accuracy: 0.9000\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2318 - accuracy: 0.9250 - val_loss: 0.2784 - val_accuracy: 0.9000\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2287 - accuracy: 0.9333 - val_loss: 0.2750 - val_accuracy: 0.9333\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2257 - accuracy: 0.9333 - val_loss: 0.2720 - val_accuracy: 0.9333\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2230 - accuracy: 0.9250 - val_loss: 0.2694 - val_accuracy: 0.9333\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2204 - accuracy: 0.9250 - val_loss: 0.2665 - val_accuracy: 0.9333\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2170 - accuracy: 0.9250 - val_loss: 0.2637 - val_accuracy: 0.9333\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2141 - accuracy: 0.9250 - val_loss: 0.2610 - val_accuracy: 0.9333\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2114 - accuracy: 0.9250 - val_loss: 0.2582 - val_accuracy: 0.9333\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2090 - accuracy: 0.9250 - val_loss: 0.2558 - val_accuracy: 0.9333\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2076 - accuracy: 0.9333 - val_loss: 0.2542 - val_accuracy: 0.9333\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2032 - accuracy: 0.9333 - val_loss: 0.2511 - val_accuracy: 0.9333\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2004 - accuracy: 0.9333 - val_loss: 0.2488 - val_accuracy: 0.9333\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1985 - accuracy: 0.9417 - val_loss: 0.2465 - val_accuracy: 0.9333\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1959 - accuracy: 0.9500 - val_loss: 0.2438 - val_accuracy: 0.9333\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1927 - accuracy: 0.9333 - val_loss: 0.2416 - val_accuracy: 0.9333\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1914 - accuracy: 0.9250 - val_loss: 0.2398 - val_accuracy: 0.9333\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1896 - accuracy: 0.9250 - val_loss: 0.2376 - val_accuracy: 0.9333\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1866 - accuracy: 0.9250 - val_loss: 0.2358 - val_accuracy: 0.9333\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1859 - accuracy: 0.9333 - val_loss: 0.2341 - val_accuracy: 0.9333\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1827 - accuracy: 0.9417 - val_loss: 0.2326 - val_accuracy: 0.9333\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1817 - accuracy: 0.9500 - val_loss: 0.2315 - val_accuracy: 0.9333\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1802 - accuracy: 0.9500 - val_loss: 0.2301 - val_accuracy: 0.9333\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1780 - accuracy: 0.9500 - val_loss: 0.2278 - val_accuracy: 0.9333\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1752 - accuracy: 0.9500 - val_loss: 0.2264 - val_accuracy: 0.9333\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1731 - accuracy: 0.9417 - val_loss: 0.2250 - val_accuracy: 0.9333\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1715 - accuracy: 0.9583 - val_loss: 0.2237 - val_accuracy: 0.9333\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1699 - accuracy: 0.9500 - val_loss: 0.2224 - val_accuracy: 0.9333\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1688 - accuracy: 0.9417 - val_loss: 0.2208 - val_accuracy: 0.9333\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1663 - accuracy: 0.9583 - val_loss: 0.2201 - val_accuracy: 0.9333\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1653 - accuracy: 0.9500 - val_loss: 0.2189 - val_accuracy: 0.9333\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1633 - accuracy: 0.9500 - val_loss: 0.2186 - val_accuracy: 0.9333\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1620 - accuracy: 0.9500 - val_loss: 0.2172 - val_accuracy: 0.9333\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1624 - accuracy: 0.9500 - val_loss: 0.2160 - val_accuracy: 0.9333\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1587 - accuracy: 0.9583 - val_loss: 0.2136 - val_accuracy: 0.9333\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1592 - accuracy: 0.9500 - val_loss: 0.2129 - val_accuracy: 0.9333\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1569 - accuracy: 0.9500 - val_loss: 0.2117 - val_accuracy: 0.9333\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1548 - accuracy: 0.9583 - val_loss: 0.2113 - val_accuracy: 0.9333\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1531 - accuracy: 0.9500 - val_loss: 0.2110 - val_accuracy: 0.9333\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1536 - accuracy: 0.9500 - val_loss: 0.2113 - val_accuracy: 0.9333\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1513 - accuracy: 0.9583 - val_loss: 0.2094 - val_accuracy: 0.9333\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1492 - accuracy: 0.9583 - val_loss: 0.2073 - val_accuracy: 0.9333\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1487 - accuracy: 0.9583 - val_loss: 0.2062 - val_accuracy: 0.9333\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1476 - accuracy: 0.9583 - val_loss: 0.2054 - val_accuracy: 0.9333\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1470 - accuracy: 0.9583 - val_loss: 0.2059 - val_accuracy: 0.9333\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1458 - accuracy: 0.9500 - val_loss: 0.2044 - val_accuracy: 0.9333\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1440 - accuracy: 0.9583 - val_loss: 0.2041 - val_accuracy: 0.9333\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1432 - accuracy: 0.9500 - val_loss: 0.2044 - val_accuracy: 0.9333\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1421 - accuracy: 0.9500 - val_loss: 0.2027 - val_accuracy: 0.9333\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1403 - accuracy: 0.9583 - val_loss: 0.2022 - val_accuracy: 0.9333\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1393 - accuracy: 0.9583 - val_loss: 0.2013 - val_accuracy: 0.9333\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1382 - accuracy: 0.9583 - val_loss: 0.2005 - val_accuracy: 0.9333\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1379 - accuracy: 0.9583 - val_loss: 0.2004 - val_accuracy: 0.9333\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1362 - accuracy: 0.9583 - val_loss: 0.1993 - val_accuracy: 0.9333\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1359 - accuracy: 0.9583 - val_loss: 0.1982 - val_accuracy: 0.9333\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1345 - accuracy: 0.9583 - val_loss: 0.1981 - val_accuracy: 0.9333\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1334 - accuracy: 0.9583 - val_loss: 0.1978 - val_accuracy: 0.9333\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1338 - accuracy: 0.9583 - val_loss: 0.1984 - val_accuracy: 0.9333\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1318 - accuracy: 0.9583 - val_loss: 0.1974 - val_accuracy: 0.9333\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1310 - accuracy: 0.9583 - val_loss: 0.1970 - val_accuracy: 0.9333\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1300 - accuracy: 0.9583 - val_loss: 0.1952 - val_accuracy: 0.9333\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1295 - accuracy: 0.9583 - val_loss: 0.1945 - val_accuracy: 0.9333\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1290 - accuracy: 0.9583 - val_loss: 0.1942 - val_accuracy: 0.9333\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1276 - accuracy: 0.9583 - val_loss: 0.1940 - val_accuracy: 0.9333\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1267 - accuracy: 0.9583 - val_loss: 0.1951 - val_accuracy: 0.9333\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1265 - accuracy: 0.9583 - val_loss: 0.1940 - val_accuracy: 0.9333\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1251 - accuracy: 0.9583 - val_loss: 0.1945 - val_accuracy: 0.9333\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1249 - accuracy: 0.9583 - val_loss: 0.1944 - val_accuracy: 0.9333\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1231 - accuracy: 0.9583 - val_loss: 0.1925 - val_accuracy: 0.9333\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1243 - accuracy: 0.9583 - val_loss: 0.1911 - val_accuracy: 0.9333\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1226 - accuracy: 0.9583 - val_loss: 0.1916 - val_accuracy: 0.9333\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1212 - accuracy: 0.9583 - val_loss: 0.1916 - val_accuracy: 0.9333\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1211 - accuracy: 0.9583 - val_loss: 0.1921 - val_accuracy: 0.9333\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1196 - accuracy: 0.9583 - val_loss: 0.1914 - val_accuracy: 0.9333\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1201 - accuracy: 0.9583 - val_loss: 0.1899 - val_accuracy: 0.9333\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1191 - accuracy: 0.9667 - val_loss: 0.1898 - val_accuracy: 0.9333\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1174 - accuracy: 0.9583 - val_loss: 0.1915 - val_accuracy: 0.9333\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1171 - accuracy: 0.9583 - val_loss: 0.1916 - val_accuracy: 0.9333\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1167 - accuracy: 0.9583 - val_loss: 0.1919 - val_accuracy: 0.9333\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1157 - accuracy: 0.9583 - val_loss: 0.1903 - val_accuracy: 0.9333\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1159 - accuracy: 0.9667 - val_loss: 0.1885 - val_accuracy: 0.9333\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1147 - accuracy: 0.9667 - val_loss: 0.1878 - val_accuracy: 0.9333\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1139 - accuracy: 0.9667 - val_loss: 0.1879 - val_accuracy: 0.9333\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1136 - accuracy: 0.9667 - val_loss: 0.1891 - val_accuracy: 0.9333\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1127 - accuracy: 0.9583 - val_loss: 0.1886 - val_accuracy: 0.9333\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1116 - accuracy: 0.9583 - val_loss: 0.1883 - val_accuracy: 0.9333\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1107 - accuracy: 0.9583 - val_loss: 0.1878 - val_accuracy: 0.9333\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1107 - accuracy: 0.9667 - val_loss: 0.1871 - val_accuracy: 0.9333\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1096 - accuracy: 0.9667 - val_loss: 0.1873 - val_accuracy: 0.9333\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1089 - accuracy: 0.9667 - val_loss: 0.1873 - val_accuracy: 0.9333\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1083 - accuracy: 0.9667 - val_loss: 0.1867 - val_accuracy: 0.9333\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1074 - accuracy: 0.9667 - val_loss: 0.1871 - val_accuracy: 0.9333\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1068 - accuracy: 0.9667 - val_loss: 0.1877 - val_accuracy: 0.9333\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1061 - accuracy: 0.9667 - val_loss: 0.1877 - val_accuracy: 0.9333\n",
            "Epoch 254/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1056 - accuracy: 0.9667 - val_loss: 0.1870 - val_accuracy: 0.9333\n",
            "Epoch 255/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1057 - accuracy: 0.9667 - val_loss: 0.1864 - val_accuracy: 0.9333\n",
            "Epoch 256/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1047 - accuracy: 0.9667 - val_loss: 0.1868 - val_accuracy: 0.9333\n",
            "Epoch 257/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1037 - accuracy: 0.9667 - val_loss: 0.1877 - val_accuracy: 0.9333\n",
            "Epoch 258/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1039 - accuracy: 0.9667 - val_loss: 0.1887 - val_accuracy: 0.9333\n",
            "Epoch 259/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1039 - accuracy: 0.9667 - val_loss: 0.1863 - val_accuracy: 0.9333\n",
            "Epoch 260/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1020 - accuracy: 0.9667 - val_loss: 0.1862 - val_accuracy: 0.9333\n",
            "Epoch 261/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1025 - accuracy: 0.9667 - val_loss: 0.1843 - val_accuracy: 0.9333\n",
            "Epoch 262/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1008 - accuracy: 0.9667 - val_loss: 0.1850 - val_accuracy: 0.9333\n",
            "Epoch 263/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1002 - accuracy: 0.9667 - val_loss: 0.1858 - val_accuracy: 0.9333\n",
            "Epoch 264/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1002 - accuracy: 0.9667 - val_loss: 0.1859 - val_accuracy: 0.9333\n",
            "Epoch 265/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0998 - accuracy: 0.9667 - val_loss: 0.1892 - val_accuracy: 0.9333\n",
            "Epoch 266/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1011 - accuracy: 0.9583 - val_loss: 0.1905 - val_accuracy: 0.9333\n",
            "Epoch 267/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0986 - accuracy: 0.9667 - val_loss: 0.1853 - val_accuracy: 0.9333\n",
            "Epoch 268/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0976 - accuracy: 0.9667 - val_loss: 0.1826 - val_accuracy: 0.9333\n",
            "Epoch 269/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0996 - accuracy: 0.9667 - val_loss: 0.1813 - val_accuracy: 0.9333\n",
            "Epoch 270/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0974 - accuracy: 0.9667 - val_loss: 0.1843 - val_accuracy: 0.9333\n",
            "Epoch 271/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0972 - accuracy: 0.9667 - val_loss: 0.1888 - val_accuracy: 0.9333\n",
            "Epoch 272/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0962 - accuracy: 0.9667 - val_loss: 0.1881 - val_accuracy: 0.9333\n",
            "Epoch 273/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0962 - accuracy: 0.9667 - val_loss: 0.1856 - val_accuracy: 0.9333\n",
            "Epoch 274/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0948 - accuracy: 0.9667 - val_loss: 0.1853 - val_accuracy: 0.9333\n",
            "Epoch 275/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0952 - accuracy: 0.9667 - val_loss: 0.1848 - val_accuracy: 0.9333\n",
            "Epoch 276/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0939 - accuracy: 0.9667 - val_loss: 0.1856 - val_accuracy: 0.9333\n",
            "Epoch 277/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0947 - accuracy: 0.9667 - val_loss: 0.1879 - val_accuracy: 0.9333\n",
            "Epoch 278/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0945 - accuracy: 0.9667 - val_loss: 0.1872 - val_accuracy: 0.9333\n",
            "Epoch 279/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0933 - accuracy: 0.9667 - val_loss: 0.1832 - val_accuracy: 0.9333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f324f74f190>"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(patience=10)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "\n",
        "model.add(Dense(units=3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x=scaled_X_train, y=y_train, epochs=300, validation_data=(scaled_X_test, y_test), callbacks=[early_stop])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "metrics = pd.DataFrame(model.history.history)"
      ],
      "metadata": {
        "id": "NPWqEaaPZsNH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "QMXT_pXmZsNI",
        "outputId": "87a4fc85-be6a-4ba7-c510-d6b7ebda7614"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f324f86a210>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "metrics[['loss', 'val_loss']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56dllgbaZsNI",
        "outputId": "fcd48582-c44b-462e-dde2-10e7cd8a4b8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18320704996585846, 0.9333333373069763]"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "model.evaluate(scaled_X_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq8Q5Dd9ZsNJ",
        "outputId": "619b30f9-bc3d-4cc8-9209-78961cd9f360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ],
      "source": [
        "epochs = len(metrics)\n",
        "print(epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "8mKRGl9ZZsNK"
      },
      "outputs": [],
      "source": [
        "scaled_X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "b3UFKr59ZsNK"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
        "\n",
        "model.add(Dense(units=3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOQkLgiRZsNK",
        "outputId": "31a36d9a-b15c-4aac-e390-29f31119f806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0801 - accuracy: 0.3400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f324fc38650>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "model.fit(scaled_X, y, epsochs=epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "s-V9SUm2ZsNK"
      },
      "outputs": [],
      "source": [
        "model.save(\"iris_classifier.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o736bH1AZsNL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSMnvRxIZsNL",
        "outputId": "ae3bcc44-316e-41a3-89b6-2356d17ec810"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['iris_classifier.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(scaler, 'iris_classifier.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "xGRRQPRjZsNL"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "iris_classifier = load_model('final_iris_model.h5')\n",
        "flower_scaler = joblib.load(\"iris_classifier.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "ZnBLZzA-ZsNM"
      },
      "outputs": [],
      "source": [
        "flower_test = {\"sepal_length\": 5.6,\n",
        "                  \"sepal_width\": 2.9,\n",
        "                  \"petal_length\": 4,\n",
        "                  \"petal_width\": 1.2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFROX5MNZsNN",
        "outputId": "1cde35b4-cd91-4b00-dc6a-91ad9c0aad8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['versicolor']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_iris_prediction(model, scaler, request):\n",
        "    sepal_length = request[\"sepal_length\"]\n",
        "    sepal_width = request[\"sepal_width\"]\n",
        "    petal_length = request[\"petal_length\"]\n",
        "    petal_width = request[\"petal_width\"]\n",
        "    \n",
        "    flower = [[sepal_length, sepal_width, petal_length, petal_width]]\n",
        "    flower = scaler.transform(flower)\n",
        "    \n",
        "    iris_classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
        "    \n",
        "    prediction = model.predict(flower)\n",
        "    class_index = np.argmax(prediction, axis=1)\n",
        "    print(iris_classes[class_index])\n",
        "\n",
        "get_iris_prediction(iris_classifier, flower_scaler, flower_test)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "iris_classifier_implementation.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}